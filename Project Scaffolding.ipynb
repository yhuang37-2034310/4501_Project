{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1VERPjEZcC1XSs4-02aM-DbkNr_yaJVbFjLJxaYQswqA/edit#)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "10434bfd-2214-4f09-bd1e-5d342f60c17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /opt/anaconda3/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (1.26.4)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (0.10.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (23.2)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (2.2.2)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (3.6.1)\n",
      "Requirement already satisfied: shapely>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (2.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from pyogrio>=0.7.2->geopandas) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "\n",
    "import os\n",
    "\n",
    "import bs4\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import geopandas as gpd\n",
    "import math\n",
    "import glob\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import sqlalchemy as db\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants you might need; some have been added for you, and \n",
    "# some you need to fill in\n",
    "\n",
    "TLC_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "PARQUET_FILES = \"parquet_files\"\n",
    "TAXI_ZONES_DIR = \"taxi_zones\"\n",
    "TAXI_ZONES_SHAPEFILE = f\"{TAXI_ZONES_DIR}/taxi_zones.shp\"\n",
    "WEATHER_CSV_DIR = \"weather_data\"\n",
    "\n",
    "#CRS = 4326  # coordinate reference system\n",
    "\n",
    "# (lat, lon)\n",
    "#NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "LGA_BOX_COORDS = ((40.763589, -73.891745), (40.778865, -73.854838))\n",
    "JFK_BOX_COORDS = ((40.639263, -73.795642), (40.651376, -73.766264))\n",
    "EWR_BOX_COORDS = ((40.686794, -74.194028), (40.699680, -74.165205))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d6601633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "try:\n",
    "    os.mkdir(QUERY_DIRECTORY)\n",
    "except Exception as e:\n",
    "    if e.errno == 17:\n",
    "        # the directory already exists\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be67f9a-979b-429c-805e-95b05b023728",
   "metadata": {},
   "source": [
    "### Download All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ae91409-8d6a-4fb9-a26a-70a1487ed0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_urls_from_tlc_page():\n",
    "    response = requests.get(TLC_URL)\n",
    "    html = response.content\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f70e242-38bb-431f-abb3-b0405beb1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifies all of the yellow and fhvhv parquet files for years 2020 - 2024\n",
    "pattern = re.compile(r\".*(yellow|fhvhv).*(2020|2021|2022|2023|2024)-\\d{2}\\.parquet\")\n",
    "\n",
    "def filter_parquet_urls():\n",
    "    html = get_all_urls_from_tlc_page()\n",
    "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    urls = soup.find_all(\"a\", href=pattern)\n",
    "    parquet_urls = [link[\"href\"].strip() for link in urls]\n",
    "    return parquet_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c8e93ae-18cb-4edf-aaec-bec22b88b000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'parquet_files' already exists.\n"
     ]
    }
   ],
   "source": [
    "folder_name = \"parquet_files\"\n",
    "\n",
    "# Check if the folder exists\n",
    "if not os.path.exists(folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "    print(f\"Folder '{folder_name}' created successfully!\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_name}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b99805f5-a06a-4324-8c97-692e7a7f9ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parses the filename from the link and then downloads the files one by one\n",
    "def download_parquet_files():\n",
    "    for link in filter_parquet_urls():\n",
    "        filename = link.split(\"/\")[-1]\n",
    "        r = requests.get(link)\n",
    "        with open(f\"parquet_files/{filename}\", \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "\n",
    "#run the first time to download data\n",
    "#download_parquet_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d53e24",
   "metadata": {},
   "source": [
    "### Load Taxi Zones & Parquet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "58708809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads the shape file\n",
    "def load_taxi_zones(shapefile):\n",
    "    taxi_zones = gpd.read_file(shapefile)\n",
    "    return taxi_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f8171ce1-7305-4091-b7ba-72f6a7799987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OBJECTID  Shape_Leng  Shape_Area                     zone  LocationID  \\\n",
      "0         1    0.116357    0.000782           Newark Airport           1   \n",
      "1         2    0.433470    0.004866              Jamaica Bay           2   \n",
      "2         3    0.084341    0.000314  Allerton/Pelham Gardens           3   \n",
      "3         4    0.043567    0.000112            Alphabet City           4   \n",
      "4         5    0.092146    0.000498            Arden Heights           5   \n",
      "\n",
      "         borough                                           geometry  \n",
      "0            EWR  POLYGON ((9.33e+05 1.93e+05, 9.33e+05 1.93e+05...  \n",
      "1         Queens  MULTIPOLYGON (((1.03e+06 1.72e+05, 1.03e+06 1....  \n",
      "2          Bronx  POLYGON ((1.03e+06 2.57e+05, 1.03e+06 2.57e+05...  \n",
      "3      Manhattan  POLYGON ((9.92e+05 2.04e+05, 9.92e+05 2.04e+05...  \n",
      "4  Staten Island  POLYGON ((9.36e+05 1.44e+05, 9.36e+05 1.44e+05...  \n"
     ]
    }
   ],
   "source": [
    "gdf_taxi_zones = load_taxi_zones(TAXI_ZONES_SHAPEFILE)\n",
    "print(gdf_taxi_zones.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "64f2431c-4839-469e-a375-327a698e4356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>zone</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>borough</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.116357</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>POLYGON ((-74.184 40.695, -74.184 40.695, -74....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.433470</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>MULTIPOLYGON (((-73.823 40.639, -73.823 40.636...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.084341</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((-73.848 40.871, -73.847 40.871, -73....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((-73.972 40.726, -73.972 40.726, -73....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.092146</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>POLYGON ((-74.174 40.563, -74.173 40.562, -74....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>259</td>\n",
       "      <td>0.126750</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>Woodlawn/Wakefield</td>\n",
       "      <td>259</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((-73.851 40.91, -73.852 40.909, -73.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>260</td>\n",
       "      <td>0.133514</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>Woodside</td>\n",
       "      <td>260</td>\n",
       "      <td>Queens</td>\n",
       "      <td>POLYGON ((-73.902 40.761, -73.901 40.76, -73.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>0.027120</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>World Trade Center</td>\n",
       "      <td>261</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((-74.013 40.705, -74.013 40.705, -74....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>262</td>\n",
       "      <td>0.049064</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>Yorkville East</td>\n",
       "      <td>262</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>MULTIPOLYGON (((-73.944 40.783, -73.944 40.783...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>263</td>\n",
       "      <td>0.037017</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>263</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((-73.952 40.773, -73.953 40.772, -73....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     OBJECTID  Shape_Leng  Shape_Area                     zone  LocationID  \\\n",
       "0           1    0.116357    0.000782           Newark Airport           1   \n",
       "1           2    0.433470    0.004866              Jamaica Bay           2   \n",
       "2           3    0.084341    0.000314  Allerton/Pelham Gardens           3   \n",
       "3           4    0.043567    0.000112            Alphabet City           4   \n",
       "4           5    0.092146    0.000498            Arden Heights           5   \n",
       "..        ...         ...         ...                      ...         ...   \n",
       "258       259    0.126750    0.000395       Woodlawn/Wakefield         259   \n",
       "259       260    0.133514    0.000422                 Woodside         260   \n",
       "260       261    0.027120    0.000034       World Trade Center         261   \n",
       "261       262    0.049064    0.000122           Yorkville East         262   \n",
       "262       263    0.037017    0.000066           Yorkville West         263   \n",
       "\n",
       "           borough                                           geometry  \n",
       "0              EWR  POLYGON ((-74.184 40.695, -74.184 40.695, -74....  \n",
       "1           Queens  MULTIPOLYGON (((-73.823 40.639, -73.823 40.636...  \n",
       "2            Bronx  POLYGON ((-73.848 40.871, -73.847 40.871, -73....  \n",
       "3        Manhattan  POLYGON ((-73.972 40.726, -73.972 40.726, -73....  \n",
       "4    Staten Island  POLYGON ((-74.174 40.563, -74.173 40.562, -74....  \n",
       "..             ...                                                ...  \n",
       "258          Bronx  POLYGON ((-73.851 40.91, -73.852 40.909, -73.8...  \n",
       "259         Queens  POLYGON ((-73.902 40.761, -73.901 40.76, -73.9...  \n",
       "260      Manhattan  POLYGON ((-74.013 40.705, -74.013 40.705, -74....  \n",
       "261      Manhattan  MULTIPOLYGON (((-73.944 40.783, -73.944 40.783...  \n",
       "262      Manhattan  POLYGON ((-73.952 40.773, -73.953 40.772, -73....  \n",
       "\n",
       "[263 rows x 7 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converts taxi zone geometry coordinates to the appropriate coordinate system  \n",
    "gdf_taxi_zones = gdf_taxi_zones.to_crs(epsg=4326)\n",
    "gdf_taxi_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4f6da777-79a3-48f2-8871-0d2d9c3aa0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load parquet file into a pandas DataFrame\n",
    "def load_parquet_file(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "45a6df80-fe06-41ab-97bc-800f117a9c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         2  2023-01-01 00:32:10   2023-01-01 00:40:36              1.0   \n",
      "1         2  2023-01-01 00:55:08   2023-01-01 01:01:27              1.0   \n",
      "2         2  2023-01-01 00:25:04   2023-01-01 00:37:49              1.0   \n",
      "3         1  2023-01-01 00:03:48   2023-01-01 00:13:25              0.0   \n",
      "4         2  2023-01-01 00:10:29   2023-01-01 00:21:19              1.0   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0           0.97         1.0                  N           161           141   \n",
      "1           1.10         1.0                  N            43           237   \n",
      "2           2.51         1.0                  N            48           238   \n",
      "3           1.90         1.0                  N           138             7   \n",
      "4           1.43         1.0                  N           107            79   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0             2          9.3   1.00      0.5        0.00           0.0   \n",
      "1             1          7.9   1.00      0.5        4.00           0.0   \n",
      "2             1         14.9   1.00      0.5       15.00           0.0   \n",
      "3             1         12.1   7.25      0.5        0.00           0.0   \n",
      "4             1         11.4   1.00      0.5        3.28           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
      "0                    1.0         14.30                   2.5         0.00  \n",
      "1                    1.0         16.90                   2.5         0.00  \n",
      "2                    1.0         34.90                   2.5         0.00  \n",
      "3                    1.0         20.85                   0.0         1.25  \n",
      "4                    1.0         19.68                   2.5         0.00  \n"
     ]
    }
   ],
   "source": [
    "# load a random yellow taxi trip parquet file to check if the function works correctly for testing purposes\n",
    "example = os.path.join(PARQUET_FILES, \"yellow_tripdata_2023-01.parquet\")\n",
    "example_df = load_parquet_file(example)\n",
    "\n",
    "# preview the data\n",
    "print(example_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "09fc14f2-021e-4222-a592-b77e25aa3882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  hvfhs_license_num dispatching_base_num originating_base_num  \\\n",
      "0            HV0003               B03404               B03404   \n",
      "1            HV0003               B03404               B03404   \n",
      "2            HV0003               B03404               B03404   \n",
      "3            HV0003               B03404               B03404   \n",
      "4            HV0003               B03404               B03404   \n",
      "\n",
      "     request_datetime   on_scene_datetime     pickup_datetime  \\\n",
      "0 2023-01-01 00:18:06 2023-01-01 00:19:24 2023-01-01 00:19:38   \n",
      "1 2023-01-01 00:48:42 2023-01-01 00:56:20 2023-01-01 00:58:39   \n",
      "2 2023-01-01 00:15:35 2023-01-01 00:20:14 2023-01-01 00:20:27   \n",
      "3 2023-01-01 00:35:24 2023-01-01 00:39:30 2023-01-01 00:41:05   \n",
      "4 2023-01-01 00:43:15 2023-01-01 00:51:10 2023-01-01 00:52:47   \n",
      "\n",
      "     dropoff_datetime  PULocationID  DOLocationID  trip_miles  ...  sales_tax  \\\n",
      "0 2023-01-01 00:48:07            48            68        0.94  ...       2.30   \n",
      "1 2023-01-01 01:33:08           246           163        2.78  ...       5.34   \n",
      "2 2023-01-01 00:37:54             9           129        8.81  ...       2.16   \n",
      "3 2023-01-01 00:48:16           129           129        0.67  ...       1.22   \n",
      "4 2023-01-01 01:04:51           129            92        4.38  ...       1.82   \n",
      "\n",
      "   congestion_surcharge  airport_fee  tips  driver_pay  shared_request_flag  \\\n",
      "0                  2.75          0.0  5.22       27.83                    N   \n",
      "1                  2.75          0.0  0.00       50.15                    N   \n",
      "2                  0.00          0.0  0.00       20.22                    N   \n",
      "3                  0.00          0.0  0.00        7.90                    N   \n",
      "4                  0.00          0.0  0.00       16.48                    N   \n",
      "\n",
      "   shared_match_flag  access_a_ride_flag  wav_request_flag wav_match_flag  \n",
      "0                  N                                     N              N  \n",
      "1                  N                                     N              N  \n",
      "2                  N                                     N              N  \n",
      "3                  N                                     N              N  \n",
      "4                  N                                     N              N  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# load a random High-Volume For-Hire Vehicle trip parquet file to check if the function works correctly\n",
    "example2 = os.path.join(PARQUET_FILES, \"fhvhv_tripdata_2023-01.parquet\")\n",
    "example_df2 = load_parquet_file(example2)\n",
    "\n",
    "# preview the data\n",
    "print(example_df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4c8ea86a-5f05-4c0a-80d8-4c3a22b318bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hvfhs_license_num', 'dispatching_base_num', 'originating_base_num',\n",
       "       'request_datetime', 'on_scene_datetime', 'pickup_datetime',\n",
       "       'dropoff_datetime', 'PULocationID', 'DOLocationID', 'trip_miles',\n",
       "       'trip_time', 'base_passenger_fare', 'tolls', 'bcf', 'sales_tax',\n",
       "       'congestion_surcharge', 'airport_fee', 'tips', 'driver_pay',\n",
       "       'shared_request_flag', 'shared_match_flag', 'access_a_ride_flag',\n",
       "       'wav_request_flag', 'wav_match_flag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "054df826-d223-42e1-a063-e8950b87e59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
       "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
       "       'total_amount', 'congestion_surcharge', 'airport_fee'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e226fb-c4e8-4548-8e42-d30100b34707",
   "metadata": {},
   "source": [
    "### Cleaning and Filtering\n",
    "* Remove all non-Uber data from fhvhv\n",
    "* Remove all invalid pickup and dropoff location IDs for both uber and yellow taxi, where ID is greater than 263 using the `shp` file\n",
    "* Remove unnecessary columns and only keeping columns needed to answer questions in the other parts of this project\n",
    "* Remove invalid data points (use your discretion!)\n",
    "* normalize column names; \n",
    "normalieg and using appropriate column types for the respective dat\n",
    "\n",
    "* Remove trips from both uber and yellow taxi that start and/or end outside of the following latitude/longitude coordinate box: (40.560445, -74.242330) and (40.908524, -73.71704).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5acd1bf2-2e19-49a5-a944-9216dcaf0bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/z6g_m0_n659dtcmkkgf76pv40000gn/T/ipykernel_30577/103723099.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf_taxi_zones['centroid'] = gdf_taxi_zones.geometry.centroid\n"
     ]
    }
   ],
   "source": [
    "#Compute the center of the taxi zones for easier comparison and adds a column to the df of our shapefile \n",
    "gdf_taxi_zones['centroid'] = gdf_taxi_zones.geometry.centroid\n",
    "\n",
    "#Rename 'LocationID' to 'location_id' for consistency\n",
    "gdf_taxi_zones = gdf_taxi_zones.rename(columns={'LocationID': 'location_id'})\n",
    "\n",
    "#Removes the bulky geometry column after using it to compute centroid. \n",
    "gdf_taxi_zones = gdf_taxi_zones[['zone', 'location_id', 'centroid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f9f09b68-041e-4cac-a0b5-591d043274e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone</th>\n",
       "      <th>location_id</th>\n",
       "      <th>centroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (-74.174 40.692)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>2</td>\n",
       "      <td>POINT (-73.831 40.617)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>3</td>\n",
       "      <td>POINT (-73.847 40.864)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>4</td>\n",
       "      <td>POINT (-73.977 40.724)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>5</td>\n",
       "      <td>POINT (-74.188 40.553)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Woodlawn/Wakefield</td>\n",
       "      <td>259</td>\n",
       "      <td>POINT (-73.852 40.898)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Woodside</td>\n",
       "      <td>260</td>\n",
       "      <td>POINT (-73.906 40.744)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>World Trade Center</td>\n",
       "      <td>261</td>\n",
       "      <td>POINT (-74.013 40.709)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Yorkville East</td>\n",
       "      <td>262</td>\n",
       "      <td>POINT (-73.947 40.776)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>263</td>\n",
       "      <td>POINT (-73.951 40.779)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        zone  location_id                centroid\n",
       "0             Newark Airport            1  POINT (-74.174 40.692)\n",
       "1                Jamaica Bay            2  POINT (-73.831 40.617)\n",
       "2    Allerton/Pelham Gardens            3  POINT (-73.847 40.864)\n",
       "3              Alphabet City            4  POINT (-73.977 40.724)\n",
       "4              Arden Heights            5  POINT (-74.188 40.553)\n",
       "..                       ...          ...                     ...\n",
       "258       Woodlawn/Wakefield          259  POINT (-73.852 40.898)\n",
       "259                 Woodside          260  POINT (-73.906 40.744)\n",
       "260       World Trade Center          261  POINT (-74.013 40.709)\n",
       "261           Yorkville East          262  POINT (-73.947 40.776)\n",
       "262           Yorkville West          263  POINT (-73.951 40.779)\n",
       "\n",
       "[263 rows x 3 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_taxi_zones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculate Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ae9ffcb8-7268-45ba-af74-752e9710a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default: 95% confidence interval, 5% margin of error, p of 0.5 (estimated) proportion of the population which has the attribute in question\n",
    "def cochran_sample_size(population_size):\n",
    "    z_score=1.96\n",
    "    margin_of_error=0.05\n",
    "    p=0.5\n",
    "    sample_size = ((z_score**2)*p*(1-p)) / (margin_of_error**2)\n",
    "    adjusted_sample_size = sample_size / (1 + ((sample_size-1)/population_size))\n",
    "\n",
    "    return int(adjusted_sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33eed4-b2e9-4ab3-94a8-59f04e464c98",
   "metadata": {},
   "source": [
    "### Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f506ca76-802b-414c-a2b0-3389bc66dfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter function to remove unecessary rows\n",
    "def filter_data(data):\n",
    "    #Ensure PU and DO locations are within valid location IDs (<= 263)\n",
    "    data = data[(data['pickup_location_id'] <= 263) & (data['dropoff_location_id'] <= 263)]\n",
    "    #Filters out rides where pickup and dropoff locations are the same\n",
    "    filtered_data = data[data['trip_distance'] != 0]\n",
    "        \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8504d167-f1f2-45ee-878f-14a802f71de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes trips from both uber and yellow taxi that start and/or end outside of the following latitude/longitude coordinate box:\n",
    "def find_centroid(data):\n",
    "    LAT_MIN, LON_MIN = 40.560445, -74.242330\n",
    "    LAT_MAX, LON_MAX = 40.908524, -73.717047\n",
    "    \n",
    "    # Extract latitude and longitude from the 'centroid' column using .apply()\n",
    "    data['centroid_lat'] = data['centroid'].apply(lambda point: point.y)\n",
    "    data['centroid_lon'] = data['centroid'].apply(lambda point: point.x)\n",
    "    \n",
    "    # Filter rows where the centroid coordinates are within the bounding coordinate box\n",
    "    centroid_data = data[\n",
    "        (data['centroid_lat'] >= LAT_MIN) & (data['centroid_lat'] <= LAT_MAX) &\n",
    "        (data['centroid_lon'] >= LON_MIN) & (data['centroid_lon'] <= LON_MAX)\n",
    "    ]\n",
    "    return centroid_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Process Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1a35b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab all of the parquet files in the directory. glob.glob is used to identify/match the pattern, path.join retrieves all the paths \n",
    "all_taxi_parquet_files = glob.glob(os.path.join(PARQUET_FILES, \"*yellow*.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1c7f09ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/z6g_m0_n659dtcmkkgf76pv40000gn/T/ipykernel_30577/4192337244.py:39: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  sampled_taxi_data = pd.concat(sampled_taxi_dfs)\n"
     ]
    }
   ],
   "source": [
    "taxi_columns_mapping = {\n",
    "    'tpep_pickup_datetime': 'pickup_datetime',\n",
    "    'tpep_dropoff_datetime': 'dropoff_datetime',\n",
    "    'extra': 'rush_hour_surcharge',\n",
    "    'PULocationID': 'pickup_location_id',\n",
    "    'DOLocationID': 'dropoff_location_id',\n",
    "     'fare_amount': 'base_passenger_fare',\n",
    "    'RatecodeID': 'rate_code_id'\n",
    "}\n",
    "\n",
    "#Make a list of just the columns we need for analysis\n",
    "columns_to_keep = [\n",
    "    'pickup_datetime', 'dropoff_datetime', 'trip_distance', 'rate_code_id',\n",
    "    'pickup_location_id', 'dropoff_location_id', 'base_passenger_fare', 'rush_hour_surcharge', 'mta_tax',\n",
    "    'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount',\n",
    "    'congestion_surcharge', 'airport_fee'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "#Create samples of all taxi parquet files according to cochran's sample size formula. Later, we concatenate all sample dfs into one df. \n",
    "sampled_taxi_dfs = []\n",
    "\n",
    "for file_path in all_taxi_parquet_files:      \n",
    "    taxi_df = load_parquet_file(file_path) #Makes a df for every parquet file \n",
    "    taxi_df = taxi_df.rename(columns=taxi_columns_mapping)\n",
    "    \n",
    "    population_size = len(taxi_df)\n",
    "    sample_size = cochran_sample_size(population_size)\n",
    "    sampled_taxi_df = taxi_df.sample(n=sample_size, random_state=42)\n",
    "    #We found that there were a few files that did not have airport_fee as a column. We populate airport_fee with NaN for such parquet files.\n",
    "    for col in columns_to_keep:  \n",
    "        if col not in sampled_taxi_df.columns:\n",
    "            sampled_taxi_df[col] = np.nan \n",
    "    sampled_taxi_df = sampled_taxi_df[columns_to_keep]\n",
    "    sampled_taxi_dfs.append(sampled_taxi_df)\n",
    "\n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "sampled_taxi_data = pd.concat(sampled_taxi_dfs)\n",
    "\n",
    "sampled_taxi_data = filter_data(sampled_taxi_data)\n",
    "\n",
    "# Make a single df that includes the taxi rides and their corresponding coordinates by merging the shape file with the ride files.\n",
    "final_taxi_data = pd.merge(sampled_taxi_data, gdf_taxi_zones, left_on = 'pickup_location_id', right_on = 'location_id', how=\"inner\")\n",
    "\n",
    "final_taxi_data = find_centroid(final_taxi_data)\n",
    "\n",
    "#Drop the centroid column, and just keep the latitude and longitude columns as that is more compatible for SQL \n",
    "final_taxi_data = final_taxi_data.drop(columns=['centroid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "10ebd75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>rate_code_id</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>dropoff_location_id</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>rush_hour_surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>zone</th>\n",
       "      <th>location_id</th>\n",
       "      <th>centroid_lat</th>\n",
       "      <th>centroid_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-28 08:27:09</td>\n",
       "      <td>2023-06-28 09:21:52</td>\n",
       "      <td>10.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138</td>\n",
       "      <td>144</td>\n",
       "      <td>57.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>17.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.44</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LaGuardia Airport</td>\n",
       "      <td>138</td>\n",
       "      <td>40.774375</td>\n",
       "      <td>-73.873629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-13 22:05:38</td>\n",
       "      <td>2023-06-13 22:10:48</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>263</td>\n",
       "      <td>237</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.20</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>263</td>\n",
       "      <td>40.778765</td>\n",
       "      <td>-73.951010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-09 10:25:49</td>\n",
       "      <td>2023-06-09 10:41:51</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>162</td>\n",
       "      <td>236</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.60</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Midtown East</td>\n",
       "      <td>162</td>\n",
       "      <td>40.756687</td>\n",
       "      <td>-73.972356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-28 15:56:14</td>\n",
       "      <td>2023-06-28 17:22:03</td>\n",
       "      <td>18.90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>229</td>\n",
       "      <td>1</td>\n",
       "      <td>114.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.65</td>\n",
       "      <td>22.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sutton Place/Turtle Bay North</td>\n",
       "      <td>229</td>\n",
       "      <td>40.756728</td>\n",
       "      <td>-73.965146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-06-22 07:12:42</td>\n",
       "      <td>2023-06-22 07:23:47</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "      <td>74</td>\n",
       "      <td>11.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Central Park</td>\n",
       "      <td>43</td>\n",
       "      <td>40.782478</td>\n",
       "      <td>-73.965553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pickup_datetime    dropoff_datetime  trip_distance  rate_code_id  \\\n",
       "0 2023-06-28 08:27:09 2023-06-28 09:21:52          10.22           1.0   \n",
       "1 2023-06-13 22:05:38 2023-06-13 22:10:48           0.80           1.0   \n",
       "2 2023-06-09 10:25:49 2023-06-09 10:41:51           1.62           1.0   \n",
       "3 2023-06-28 15:56:14 2023-06-28 17:22:03          18.90           3.0   \n",
       "4 2023-06-22 07:12:42 2023-06-22 07:23:47           1.52           1.0   \n",
       "\n",
       "   pickup_location_id  dropoff_location_id  base_passenger_fare  \\\n",
       "0                 138                  144                 57.6   \n",
       "1                 263                  237                  7.2   \n",
       "2                 162                  236                 15.6   \n",
       "3                 229                    1                114.7   \n",
       "4                  43                   74                 11.4   \n",
       "\n",
       "   rush_hour_surcharge  mta_tax  tip_amount  tolls_amount  \\\n",
       "0                  5.0      0.5       17.09          0.00   \n",
       "1                  3.5      0.5        0.00          0.00   \n",
       "2                  0.0      0.5        2.00          0.00   \n",
       "3                  0.0      0.0       27.65         22.75   \n",
       "4                  0.0      0.5        1.94          0.00   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \\\n",
       "0                    1.0         85.44                   2.5          NaN   \n",
       "1                    1.0         12.20                   2.5          NaN   \n",
       "2                    1.0         21.60                   2.5          NaN   \n",
       "3                    1.0        166.10                   0.0          NaN   \n",
       "4                    1.0         14.84                   0.0          NaN   \n",
       "\n",
       "                            zone  location_id  centroid_lat  centroid_lon  \n",
       "0              LaGuardia Airport          138     40.774375    -73.873629  \n",
       "1                 Yorkville West          263     40.778765    -73.951010  \n",
       "2                   Midtown East          162     40.756687    -73.972356  \n",
       "3  Sutton Place/Turtle Bay North          229     40.756728    -73.965146  \n",
       "4                   Central Park           43     40.782478    -73.965553  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_taxi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c9da7089-3f6b-4f93-a22e-76bf554daca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20826 entries, 0 to 20828\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   pickup_datetime        20826 non-null  datetime64[us]\n",
      " 1   dropoff_datetime       20826 non-null  datetime64[us]\n",
      " 2   trip_distance          20826 non-null  float64       \n",
      " 3   rate_code_id           19770 non-null  float64       \n",
      " 4   pickup_location_id     20826 non-null  int64         \n",
      " 5   dropoff_location_id    20826 non-null  int64         \n",
      " 6   base_passenger_fare    20826 non-null  float64       \n",
      " 7   rush_hour_surcharge    20826 non-null  float64       \n",
      " 8   mta_tax                20826 non-null  float64       \n",
      " 9   tip_amount             20826 non-null  float64       \n",
      " 10  tolls_amount           20826 non-null  float64       \n",
      " 11  improvement_surcharge  20826 non-null  float64       \n",
      " 12  total_amount           20826 non-null  float64       \n",
      " 13  congestion_surcharge   19770 non-null  float64       \n",
      " 14  airport_fee            7947 non-null   float64       \n",
      " 15  zone                   20826 non-null  object        \n",
      " 16  location_id            20826 non-null  int32         \n",
      " 17  centroid               20826 non-null  geometry      \n",
      " 18  centroid_lat           20826 non-null  float64       \n",
      " 19  centroid_lon           20826 non-null  float64       \n",
      "dtypes: datetime64[us](2), float64(13), geometry(1), int32(1), int64(2), object(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "final_taxi_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "50c85e25-6416-4c16-b98c-09596cdc6865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>rate_code_id</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>dropoff_location_id</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>rush_hour_surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>location_id</th>\n",
       "      <th>centroid_lat</th>\n",
       "      <th>centroid_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20826</td>\n",
       "      <td>20826</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>19770.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>19770.000000</td>\n",
       "      <td>7947.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-05-01 10:17:07.596273</td>\n",
       "      <td>2022-05-01 10:33:09.629309</td>\n",
       "      <td>3.275384</td>\n",
       "      <td>1.415023</td>\n",
       "      <td>164.151157</td>\n",
       "      <td>160.661001</td>\n",
       "      <td>15.153432</td>\n",
       "      <td>1.205869</td>\n",
       "      <td>0.490733</td>\n",
       "      <td>2.680401</td>\n",
       "      <td>0.431877</td>\n",
       "      <td>0.543945</td>\n",
       "      <td>22.188515</td>\n",
       "      <td>2.297547</td>\n",
       "      <td>0.086825</td>\n",
       "      <td>164.151157</td>\n",
       "      <td>40.753285</td>\n",
       "      <td>-73.966859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 00:11:06</td>\n",
       "      <td>2020-01-01 00:30:50</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-81.520000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.200000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-108.200000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.576961</td>\n",
       "      <td>-74.029892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-02-28 21:30:14.250000</td>\n",
       "      <td>2021-02-28 21:36:58.750000</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-73.989844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-04-30 15:36:52.500000</td>\n",
       "      <td>2022-04-30 16:06:25</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>40.758027</td>\n",
       "      <td>-73.977698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-06-29 14:40:03</td>\n",
       "      <td>2023-06-29 14:50:15.250000</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.360000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>-73.961763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-08-31 22:43:47</td>\n",
       "      <td>2024-08-31 23:26:23</td>\n",
       "      <td>67.900000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>209.500000</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>262.700000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>40.899529</td>\n",
       "      <td>-73.739337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.121171</td>\n",
       "      <td>6.028092</td>\n",
       "      <td>65.215425</td>\n",
       "      <td>70.490221</td>\n",
       "      <td>13.948344</td>\n",
       "      <td>1.512793</td>\n",
       "      <td>0.089069</td>\n",
       "      <td>3.157641</td>\n",
       "      <td>1.825400</td>\n",
       "      <td>0.351174</td>\n",
       "      <td>17.759500</td>\n",
       "      <td>0.735558</td>\n",
       "      <td>0.321505</td>\n",
       "      <td>65.215425</td>\n",
       "      <td>0.032466</td>\n",
       "      <td>0.045223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pickup_datetime            dropoff_datetime  trip_distance  \\\n",
       "count                       20826                       20826   20826.000000   \n",
       "mean   2022-05-01 10:17:07.596273  2022-05-01 10:33:09.629309       3.275384   \n",
       "min           2020-01-01 00:11:06         2020-01-01 00:30:50       0.010000   \n",
       "25%    2021-02-28 21:30:14.250000  2021-02-28 21:36:58.750000       1.090000   \n",
       "50%    2022-04-30 15:36:52.500000         2022-04-30 16:06:25       1.800000   \n",
       "75%           2023-06-29 14:40:03  2023-06-29 14:50:15.250000       3.310000   \n",
       "max           2024-08-31 22:43:47         2024-08-31 23:26:23      67.900000   \n",
       "std                           NaN                         NaN       4.121171   \n",
       "\n",
       "       rate_code_id  pickup_location_id  dropoff_location_id  \\\n",
       "count  19770.000000        20826.000000         20826.000000   \n",
       "mean       1.415023          164.151157           160.661001   \n",
       "min        1.000000            4.000000             1.000000   \n",
       "25%        1.000000          132.000000           107.000000   \n",
       "50%        1.000000          162.000000           161.000000   \n",
       "75%        1.000000          234.000000           234.000000   \n",
       "max       99.000000          263.000000           263.000000   \n",
       "std        6.028092           65.215425            70.490221   \n",
       "\n",
       "       base_passenger_fare  rush_hour_surcharge       mta_tax    tip_amount  \\\n",
       "count         20826.000000         20826.000000  20826.000000  20826.000000   \n",
       "mean             15.153432             1.205869      0.490733      2.680401   \n",
       "min             -81.520000            -7.500000     -0.500000      0.000000   \n",
       "25%               7.200000             0.000000      0.500000      0.000000   \n",
       "50%              10.700000             0.500000      0.500000      2.160000   \n",
       "75%              17.000000             2.500000      0.500000      3.440000   \n",
       "max             209.500000            11.750000      0.500000     50.000000   \n",
       "std              13.948344             1.512793      0.089069      3.157641   \n",
       "\n",
       "       tolls_amount  improvement_surcharge  total_amount  \\\n",
       "count  20826.000000           20826.000000  20826.000000   \n",
       "mean       0.431877               0.543945     22.188515   \n",
       "min      -34.200000              -1.000000   -108.200000   \n",
       "25%        0.000000               0.300000     12.600000   \n",
       "50%        0.000000               0.300000     16.800000   \n",
       "75%        0.000000               1.000000     24.360000   \n",
       "max       40.000000               1.000000    262.700000   \n",
       "std        1.825400               0.351174     17.759500   \n",
       "\n",
       "       congestion_surcharge  airport_fee   location_id  centroid_lat  \\\n",
       "count          19770.000000  7947.000000  20826.000000  20826.000000   \n",
       "mean               2.297547     0.086825    164.151157     40.753285   \n",
       "min               -2.500000    -1.250000      4.000000     40.576961   \n",
       "25%                2.500000     0.000000    132.000000     40.740337   \n",
       "50%                2.500000     0.000000    162.000000     40.758027   \n",
       "75%                2.500000     0.000000    234.000000     40.773633   \n",
       "max                2.500000     1.250000    263.000000     40.899529   \n",
       "std                0.735558     0.321505     65.215425      0.032466   \n",
       "\n",
       "       centroid_lon  \n",
       "count  20826.000000  \n",
       "mean     -73.966859  \n",
       "min      -74.029892  \n",
       "25%      -73.989844  \n",
       "50%      -73.977698  \n",
       "75%      -73.961763  \n",
       "max      -73.739337  \n",
       "std        0.045223  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_taxi_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0d0658d4-173f-4290-abd8-022b5b9e5560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab all of the parquet files in the directory. glob.glob is used to identify/match the pattern, path.join retrieves all the paths \n",
    "all_fhvhv_parquet_files = glob.glob(os.path.join(PARQUET_FILES, \"*fhvhv*.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4c4a1fb4-01b4-43ff-b5e7-492ce2fc3bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/z6g_m0_n659dtcmkkgf76pv40000gn/T/ipykernel_30577/3122417029.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  sampled_uber_data = pd.concat(sampled_uber_dfs)\n"
     ]
    }
   ],
   "source": [
    "uber_columns_mapping = {\n",
    "    'trip_miles': 'trip_distance',\n",
    "    'PULocationID': 'pickup_location_id',\n",
    "    'DOLocationID': 'dropoff_location_id',\n",
    "    'tolls': 'tolls_amount',\n",
    "    'tips': 'tip_amount',\n",
    "    'bcf': 'black_car_fund_fee',\n",
    "    \n",
    "}\n",
    "\n",
    "#Create samples of all uber parquet files according to cochran's sample size formula. Later, we concatenate all sample dfs into one df. \n",
    "sampled_uber_dfs = []\n",
    "columns_to_keep = ['hvfhs_license_num',\n",
    "       'request_datetime', 'pickup_datetime',\n",
    "       'dropoff_datetime', 'pickup_location_id', 'dropoff_location_id', 'trip_distance',\n",
    "        'base_passenger_fare', 'tolls_amount', 'black_car_fund_fee', 'sales_tax',\n",
    "       'congestion_surcharge', 'airport_fee', 'tip_amount']\n",
    "\n",
    "for file_path in all_fhvhv_parquet_files:      \n",
    "    uber_df = load_parquet_file(file_path) #Makes a df for every parquet file \n",
    "    uber_df = uber_df.rename(columns=uber_columns_mapping)\n",
    "    uber_df = uber_df[uber_df['hvfhs_license_num'] == 'HV0003'] #Filters out non-uber rides from the hvfhs files before creating samples\n",
    "    population_size = len(uber_df)\n",
    "    sample_size = cochran_sample_size(population_size)\n",
    "    sampled_uber_df = uber_df.sample(n=sample_size, random_state=42)\n",
    "    sampled_uber_df = sampled_uber_df[columns_to_keep]\n",
    "    sampled_uber_dfs.append(sampled_uber_df)\n",
    "\n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "sampled_uber_data = pd.concat(sampled_uber_dfs)\n",
    "\n",
    "sampled_uber_data = filter_data(sampled_uber_data)\n",
    "\n",
    "# Make a single df that includes the taxi rides and their corresponding coordinates by merging the shape file with the ride files.\n",
    "final_uber_data = pd.merge(sampled_uber_data, gdf_taxi_zones, left_on = 'pickup_location_id', right_on = 'location_id', how=\"inner\")\n",
    "\n",
    "final_uber_data = find_centroid(final_uber_data)\n",
    "\n",
    "#Remove the centroid column and just keep the latitude and longitude for SQL compatibility\n",
    "final_uber_data = final_uber_data.drop(columns=['centroid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "339997e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>dropoff_location_id</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>black_car_fund_fee</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>zone</th>\n",
       "      <th>location_id</th>\n",
       "      <th>centroid_lat</th>\n",
       "      <th>centroid_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2021-03-19 08:07:07</td>\n",
       "      <td>2021-03-19 08:11:50</td>\n",
       "      <td>2021-03-19 08:20:59</td>\n",
       "      <td>97</td>\n",
       "      <td>231</td>\n",
       "      <td>2.52</td>\n",
       "      <td>12.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.14</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fort Greene</td>\n",
       "      <td>97</td>\n",
       "      <td>40.690786</td>\n",
       "      <td>-73.974882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2021-03-01 22:02:07</td>\n",
       "      <td>2021-03-01 22:08:28</td>\n",
       "      <td>2021-03-01 22:20:19</td>\n",
       "      <td>247</td>\n",
       "      <td>20</td>\n",
       "      <td>2.41</td>\n",
       "      <td>11.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>West Concourse</td>\n",
       "      <td>247</td>\n",
       "      <td>40.828988</td>\n",
       "      <td>-73.924409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2021-03-13 05:42:59</td>\n",
       "      <td>2021-03-13 05:48:40</td>\n",
       "      <td>2021-03-13 05:55:36</td>\n",
       "      <td>18</td>\n",
       "      <td>247</td>\n",
       "      <td>2.21</td>\n",
       "      <td>15.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bedford Park</td>\n",
       "      <td>18</td>\n",
       "      <td>40.867682</td>\n",
       "      <td>-73.890183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2021-03-12 20:58:30</td>\n",
       "      <td>2021-03-12 21:02:02</td>\n",
       "      <td>2021-03-12 21:25:13</td>\n",
       "      <td>211</td>\n",
       "      <td>229</td>\n",
       "      <td>3.85</td>\n",
       "      <td>21.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SoHo</td>\n",
       "      <td>211</td>\n",
       "      <td>40.723888</td>\n",
       "      <td>-74.001537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2021-03-31 08:42:41</td>\n",
       "      <td>2021-03-31 08:49:53</td>\n",
       "      <td>2021-03-31 09:56:02</td>\n",
       "      <td>74</td>\n",
       "      <td>45</td>\n",
       "      <td>18.96</td>\n",
       "      <td>71.31</td>\n",
       "      <td>6.12</td>\n",
       "      <td>2.33</td>\n",
       "      <td>6.89</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>East Harlem North</td>\n",
       "      <td>74</td>\n",
       "      <td>40.801169</td>\n",
       "      <td>-73.937345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num    request_datetime     pickup_datetime  \\\n",
       "0            HV0003 2021-03-19 08:07:07 2021-03-19 08:11:50   \n",
       "1            HV0003 2021-03-01 22:02:07 2021-03-01 22:08:28   \n",
       "2            HV0003 2021-03-13 05:42:59 2021-03-13 05:48:40   \n",
       "3            HV0003 2021-03-12 20:58:30 2021-03-12 21:02:02   \n",
       "4            HV0003 2021-03-31 08:42:41 2021-03-31 08:49:53   \n",
       "\n",
       "     dropoff_datetime  pickup_location_id  dropoff_location_id  trip_distance  \\\n",
       "0 2021-03-19 08:20:59                  97                  231           2.52   \n",
       "1 2021-03-01 22:20:19                 247                   20           2.41   \n",
       "2 2021-03-13 05:55:36                  18                  247           2.21   \n",
       "3 2021-03-12 21:25:13                 211                  229           3.85   \n",
       "4 2021-03-31 09:56:02                  74                   45          18.96   \n",
       "\n",
       "   base_passenger_fare  tolls_amount  black_car_fund_fee  sales_tax  \\\n",
       "0                12.58          0.00                0.39       1.14   \n",
       "1                11.94          0.00                0.36       1.06   \n",
       "2                15.25          0.00                0.46       1.35   \n",
       "3                21.51          0.00                0.65       1.91   \n",
       "4                71.31          6.12                2.33       6.89   \n",
       "\n",
       "   congestion_surcharge  airport_fee  tip_amount               zone  \\\n",
       "0                  2.75          NaN         0.0        Fort Greene   \n",
       "1                  0.00          NaN         0.0     West Concourse   \n",
       "2                  0.00          NaN         0.0       Bedford Park   \n",
       "3                  2.75          NaN         0.0               SoHo   \n",
       "4                  2.75          0.0         0.0  East Harlem North   \n",
       "\n",
       "   location_id  centroid_lat  centroid_lon  \n",
       "0           97     40.690786    -73.974882  \n",
       "1          247     40.828988    -73.924409  \n",
       "2           18     40.867682    -73.890183  \n",
       "3          211     40.723888    -74.001537  \n",
       "4           74     40.801169    -73.937345  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_uber_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "74d783db-e527-4847-bf70-2d7428ea3897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20678 entries, 0 to 20731\n",
      "Data columns (total 19 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   hvfhs_license_num     20678 non-null  object        \n",
      " 1   request_datetime      20678 non-null  datetime64[us]\n",
      " 2   pickup_datetime       20678 non-null  datetime64[us]\n",
      " 3   dropoff_datetime      20678 non-null  datetime64[us]\n",
      " 4   pickup_location_id    20678 non-null  int64         \n",
      " 5   dropoff_location_id   20678 non-null  int64         \n",
      " 6   trip_distance         20678 non-null  float64       \n",
      " 7   base_passenger_fare   20678 non-null  float64       \n",
      " 8   tolls_amount          20678 non-null  float64       \n",
      " 9   black_car_fund_fee    20678 non-null  float64       \n",
      " 10  sales_tax             20678 non-null  float64       \n",
      " 11  congestion_surcharge  20678 non-null  float64       \n",
      " 12  airport_fee           15107 non-null  float64       \n",
      " 13  tip_amount            20678 non-null  float64       \n",
      " 14  zone                  20678 non-null  object        \n",
      " 15  location_id           20678 non-null  int32         \n",
      " 16  centroid              20678 non-null  geometry      \n",
      " 17  centroid_lat          20678 non-null  float64       \n",
      " 18  centroid_lon          20678 non-null  float64       \n",
      "dtypes: datetime64[us](3), float64(10), geometry(1), int32(1), int64(2), object(2)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "final_uber_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6fddeb14-cd70-4e83-8f93-974642c3bea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>dropoff_location_id</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>black_car_fund_fee</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>location_id</th>\n",
       "      <th>centroid_lat</th>\n",
       "      <th>centroid_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20678</td>\n",
       "      <td>20678</td>\n",
       "      <td>20678</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>15107.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-04-29 03:51:06.178257</td>\n",
       "      <td>2022-04-29 03:55:45.584002</td>\n",
       "      <td>2022-04-29 04:13:38.630138</td>\n",
       "      <td>137.800077</td>\n",
       "      <td>137.759745</td>\n",
       "      <td>4.439277</td>\n",
       "      <td>21.201442</td>\n",
       "      <td>0.656449</td>\n",
       "      <td>0.620884</td>\n",
       "      <td>1.895659</td>\n",
       "      <td>1.052326</td>\n",
       "      <td>0.191468</td>\n",
       "      <td>0.820059</td>\n",
       "      <td>137.800077</td>\n",
       "      <td>40.737433</td>\n",
       "      <td>-73.934434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 01:14:43</td>\n",
       "      <td>2020-01-01 01:21:23</td>\n",
       "      <td>2020-01-01 01:46:38</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-9.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.561994</td>\n",
       "      <td>-74.170887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-02-24 10:25:41.250000</td>\n",
       "      <td>2021-02-24 10:29:33.250000</td>\n",
       "      <td>2021-02-24 10:49:42.250000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>10.490000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>40.690786</td>\n",
       "      <td>-73.984196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-04-25 21:30:18</td>\n",
       "      <td>2022-04-25 21:33:31.500000</td>\n",
       "      <td>2022-04-25 21:42:09</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>16.720000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>40.737698</td>\n",
       "      <td>-73.948789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-06-30 11:11:37</td>\n",
       "      <td>2023-06-30 11:14:15</td>\n",
       "      <td>2023-06-30 11:23:13.250000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>26.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>2.380000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>40.774375</td>\n",
       "      <td>-73.898956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-08-31 23:43:36</td>\n",
       "      <td>2024-08-31 23:49:13</td>\n",
       "      <td>2024-09-01 00:10:26</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>42.660000</td>\n",
       "      <td>255.840000</td>\n",
       "      <td>43.910000</td>\n",
       "      <td>7.950000</td>\n",
       "      <td>23.510000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>40.899529</td>\n",
       "      <td>-73.726656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.489021</td>\n",
       "      <td>75.367212</td>\n",
       "      <td>4.359484</td>\n",
       "      <td>15.753046</td>\n",
       "      <td>2.520313</td>\n",
       "      <td>0.500625</td>\n",
       "      <td>1.450202</td>\n",
       "      <td>1.332477</td>\n",
       "      <td>0.670128</td>\n",
       "      <td>2.429705</td>\n",
       "      <td>75.489021</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>0.065377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 request_datetime             pickup_datetime  \\\n",
       "count                       20678                       20678   \n",
       "mean   2022-04-29 03:51:06.178257  2022-04-29 03:55:45.584002   \n",
       "min           2020-01-01 01:14:43         2020-01-01 01:21:23   \n",
       "25%    2021-02-24 10:25:41.250000  2021-02-24 10:29:33.250000   \n",
       "50%           2022-04-25 21:30:18  2022-04-25 21:33:31.500000   \n",
       "75%           2023-06-30 11:11:37         2023-06-30 11:14:15   \n",
       "max           2024-08-31 23:43:36         2024-08-31 23:49:13   \n",
       "std                           NaN                         NaN   \n",
       "\n",
       "                 dropoff_datetime  pickup_location_id  dropoff_location_id  \\\n",
       "count                       20678        20678.000000         20678.000000   \n",
       "mean   2022-04-29 04:13:38.630138          137.800077           137.759745   \n",
       "min           2020-01-01 01:46:38            3.000000             1.000000   \n",
       "25%    2021-02-24 10:49:42.250000           73.000000            74.000000   \n",
       "50%           2022-04-25 21:42:09          139.000000           138.000000   \n",
       "75%    2023-06-30 11:23:13.250000          211.000000           209.000000   \n",
       "max           2024-09-01 00:10:26          263.000000           263.000000   \n",
       "std                           NaN           75.489021            75.367212   \n",
       "\n",
       "       trip_distance  base_passenger_fare  tolls_amount  black_car_fund_fee  \\\n",
       "count   20678.000000         20678.000000  20678.000000        20678.000000   \n",
       "mean        4.439277            21.201442      0.656449            0.620884   \n",
       "min         0.020000            -9.400000      0.000000            0.000000   \n",
       "25%         1.540000            10.490000      0.000000            0.290000   \n",
       "50%         2.810000            16.720000      0.000000            0.470000   \n",
       "75%         5.710000            26.570000      0.000000            0.770000   \n",
       "max        42.660000           255.840000     43.910000            7.950000   \n",
       "std         4.359484            15.753046      2.520313            0.500625   \n",
       "\n",
       "          sales_tax  congestion_surcharge   airport_fee    tip_amount  \\\n",
       "count  20678.000000          20678.000000  15107.000000  20678.000000   \n",
       "mean       1.895659              1.052326      0.191468      0.820059   \n",
       "min        0.000000              0.000000      0.000000      0.000000   \n",
       "25%        0.910000              0.000000      0.000000      0.000000   \n",
       "50%        1.470000              0.000000      0.000000      0.000000   \n",
       "75%        2.380000              2.750000      0.000000      0.000000   \n",
       "max       23.510000              2.750000      5.000000     40.000000   \n",
       "std        1.450202              1.332477      0.670128      2.429705   \n",
       "\n",
       "        location_id  centroid_lat  centroid_lon  \n",
       "count  20678.000000  20678.000000  20678.000000  \n",
       "mean     137.800077     40.737433    -73.934434  \n",
       "min        3.000000     40.561994    -74.170887  \n",
       "25%       73.000000     40.690786    -73.984196  \n",
       "50%      139.000000     40.737698    -73.948789  \n",
       "75%      211.000000     40.774375    -73.898956  \n",
       "max      263.000000     40.899529    -73.726656  \n",
       "std       75.489021      0.069218      0.065377  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_uber_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0ec5370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_weather_csvs(directory):\n",
    "    weather_dfs = []\n",
    "\n",
    "    # Iterate over all files in the given directory\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path, low_memory=False)\n",
    "        # Append the DataFrame to the list\n",
    "        weather_dfs.append(df)\n",
    "    weather_dfs = pd.concat(weather_dfs, ignore_index=True)\n",
    "    return weather_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4ff3a175-10a4-4187-88d7-240325c3a672",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xff in position 580: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[163], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m columns_to_keep \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLATITUDE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLONGITUDE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonthlyTotalLiquidPrecipitation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDailyPrecipitation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHourlyPrecipitation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDailyAverageWindSpeed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHourlyWindSpeed\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDailySnowfall\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m weather_data \u001b[38;5;241m=\u001b[39m get_all_weather_csvs(WEATHER_CSV_DIR)\n\u001b[1;32m      4\u001b[0m weather_data \u001b[38;5;241m=\u001b[39m weather_data[columns_to_keep]\n\u001b[1;32m      5\u001b[0m weather_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(weather_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDATE\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[162], line 8\u001b[0m, in \u001b[0;36mget_all_weather_csvs\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m      6\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, filename)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Read the CSV file into a DataFrame\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Append the DataFrame to the list\u001b[39;00m\n\u001b[1;32m     10\u001b[0m weather_dfs\u001b[38;5;241m.\u001b[39mappend(df)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32mparsers.pyx:574\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:663\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xff in position 580: invalid start byte"
     ]
    }
   ],
   "source": [
    "columns_to_keep = ['DATE','LATITUDE', 'LONGITUDE', 'MonthlyTotalLiquidPrecipitation', 'DailyPrecipitation', 'HourlyPrecipitation', 'DailyAverageWindSpeed', 'HourlyWindSpeed', 'DailySnowfall']\n",
    "\n",
    "weather_data = get_all_weather_csvs(WEATHER_CSV_DIR)\n",
    "weather_data = weather_data[columns_to_keep]\n",
    "weather_data['DATE'] = pd.to_datetime(weather_data['DATE'])\n",
    "\n",
    "# weather_data[weather_data[\"DailyPrecipitation\"].isna()] #54343\n",
    "weather_data[weather_data[\"HourlyPrecipitation\"].isna()] #8,523\n",
    "# weather_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4b32ee20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [DATE, LATITUDE, LONGITUDE, MonthlyTotalLiquidPrecipitation, DailyPrecipitation, HourlyPrecipitation, DailyAverageWindSpeed, HourlyWindSpeed, DailySnowfall, DATE_ONLY]\n",
      "Index: []\n",
      "Unique String Values and Their Counts in HourlyPrecipitation:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "#We needed to do this because an error was being thrown that the hourly precipitation values were strings. \n",
    "# Identify rows where HourlyPrecipitation is a string\n",
    "string_precipitation_rows = weather_data[weather_data['HourlyPrecipitation'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "# Print or display the rows to inspect the problematic values\n",
    "print(string_precipitation_rows)\n",
    "# Identify rows where HourlyPrecipitation is a string\n",
    "string_precipitation_rows = weather_data[weather_data['HourlyPrecipitation'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "# Extract the HourlyPrecipitation values that are strings\n",
    "string_values = string_precipitation_rows['HourlyPrecipitation']\n",
    "\n",
    "# Get unique values and their count using value_counts()\n",
    "string_value_counts = string_values.value_counts()\n",
    "\n",
    "# Print or display the unique string values and their count\n",
    "print(\"Unique String Values and Their Counts in HourlyPrecipitation:\")\n",
    "print(string_value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8e18763d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 DATE  LATITUDE  LONGITUDE MonthlyTotalLiquidPrecipitation  \\\n",
      "0 2020-01-01 00:51:00  40.77898  -73.96925                             NaN   \n",
      "1 2020-01-01 01:51:00  40.77898  -73.96925                             NaN   \n",
      "2 2020-01-01 02:51:00  40.77898  -73.96925                             NaN   \n",
      "3 2020-01-01 03:51:00  40.77898  -73.96925                             NaN   \n",
      "4 2020-01-01 04:51:00  40.77898  -73.96925                             NaN   \n",
      "\n",
      "  DailyPrecipitation  HourlyPrecipitation  DailyAverageWindSpeed  \\\n",
      "0                NaN                  0.0                    NaN   \n",
      "1                NaN                  0.0                    NaN   \n",
      "2                NaN                  0.0                    NaN   \n",
      "3                NaN                  0.0                    NaN   \n",
      "4                NaN                  0.0                    NaN   \n",
      "\n",
      "   HourlyWindSpeed DailySnowfall   DATE_ONLY  \n",
      "0              8.0           NaN  2020-01-01  \n",
      "1              8.0           NaN  2020-01-01  \n",
      "2             14.0           NaN  2020-01-01  \n",
      "3             11.0           NaN  2020-01-01  \n",
      "4              6.0           NaN  2020-01-01  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/z6g_m0_n659dtcmkkgf76pv40000gn/T/ipykernel_30577/2630901844.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  weather_data['HourlyPrecipitation'].replace('T', 0.00, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Cleans out the string values based on different cases identified in the query above\n",
    "# Replace 'T' (trace amount) with 0.00\n",
    "weather_data['HourlyPrecipitation'].replace('T', 0.00, inplace=True)\n",
    "\n",
    "# Function to clean non-numeric characters from values\n",
    "def clean_precipitation_value(value):\n",
    "    if isinstance(value, str):\n",
    "        # Remove all non-numeric characters except the decimal point\n",
    "        return re.sub(r'[^0-9.]', '', value)\n",
    "    return value\n",
    "\n",
    "# Apply the cleaning function to the HourlyPrecipitation column\n",
    "weather_data['HourlyPrecipitation'] = weather_data['HourlyPrecipitation'].apply(clean_precipitation_value)\n",
    "\n",
    "# Convert all cleaned values to numeric, coercing any problematic ones to NaN\n",
    "weather_data['HourlyPrecipitation'] = pd.to_numeric(weather_data['HourlyPrecipitation'], errors='coerce')\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(weather_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "42534e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the remaining null hourly precipiation values \n",
    "# Ensure that 'DATE' is in the correct datetime format\n",
    "weather_data['DATE'] = pd.to_datetime(weather_data['DATE'])\n",
    "\n",
    "# Add a column for just the date (without time), which will help with grouping\n",
    "weather_data['DATE_ONLY'] = weather_data['DATE'].dt.date\n",
    "# Group by each unique date\n",
    "daily_groups = weather_data.groupby('DATE_ONLY')\n",
    "\n",
    "# Loop over each group of a specific date and calculate the remaining precipitation to distribute\n",
    "for date, group in daily_groups:\n",
    "    # Get the daily precipitation for the current day\n",
    "    daily_precipitation = group['DailyPrecipitation'].iloc[0]\n",
    "    \n",
    "    # Calculate the sum of existing hourly precipitation values (if any)\n",
    "    existing_hourly_precip = group['HourlyPrecipitation'].sum(skipna=True)\n",
    "\n",
    "    # Calculate the remaining precipitation that needs to be distributed to missing hours\n",
    "    remaining_precip = daily_precipitation - existing_hourly_precip\n",
    "\n",
    "    # Get the number of hours with missing HourlyPrecipitation\n",
    "    missing_hours = group['HourlyPrecipitation'].isna().sum()\n",
    "\n",
    "    # Calculate how much to distribute to each missing hour\n",
    "    if missing_hours > 0 and remaining_precip > 0:\n",
    "        hourly_precipitation_to_assign = remaining_precip / missing_hours\n",
    "    else:\n",
    "        hourly_precipitation_to_assign = 0\n",
    "\n",
    "    # Fill missing HourlyPrecipitation values with the calculated amount\n",
    "    weather_data.loc[group.index, 'HourlyPrecipitation'] = group['HourlyPrecipitation'].fillna(hourly_precipitation_to_assign)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "79d7f715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>MonthlyTotalLiquidPrecipitation</th>\n",
       "      <th>DailyPrecipitation</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>DailyAverageWindSpeed</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "      <th>DailySnowfall</th>\n",
       "      <th>DATE_ONLY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [DATE, LATITUDE, LONGITUDE, MonthlyTotalLiquidPrecipitation, DailyPrecipitation, HourlyPrecipitation, DailyAverageWindSpeed, HourlyWindSpeed, DailySnowfall, DATE_ONLY]\n",
       "Index: []"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm there are no null hourly precipitation values anymore \n",
    "weather_data[weather_data[\"HourlyPrecipitation\"].isna()] #0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "48216557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>MonthlyTotalLiquidPrecipitation</th>\n",
       "      <th>daily_precipitation</th>\n",
       "      <th>hourly_precipitation</th>\n",
       "      <th>daily_average_wind_speed</th>\n",
       "      <th>hourly_wind_speed</th>\n",
       "      <th>daily_snowfall</th>\n",
       "      <th>DATE_ONLY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 01:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 02:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 03:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 04:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  latitude  longitude MonthlyTotalLiquidPrecipitation  \\\n",
       "0 2020-01-01 00:51:00  40.77898  -73.96925                             NaN   \n",
       "1 2020-01-01 01:51:00  40.77898  -73.96925                             NaN   \n",
       "2 2020-01-01 02:51:00  40.77898  -73.96925                             NaN   \n",
       "3 2020-01-01 03:51:00  40.77898  -73.96925                             NaN   \n",
       "4 2020-01-01 04:51:00  40.77898  -73.96925                             NaN   \n",
       "\n",
       "  daily_precipitation  hourly_precipitation  daily_average_wind_speed  \\\n",
       "0                 NaN                   0.0                       NaN   \n",
       "1                 NaN                   0.0                       NaN   \n",
       "2                 NaN                   0.0                       NaN   \n",
       "3                 NaN                   0.0                       NaN   \n",
       "4                 NaN                   0.0                       NaN   \n",
       "\n",
       "   hourly_wind_speed daily_snowfall   DATE_ONLY  \n",
       "0                8.0            NaN  2020-01-01  \n",
       "1                8.0            NaN  2020-01-01  \n",
       "2               14.0            NaN  2020-01-01  \n",
       "3               11.0            NaN  2020-01-01  \n",
       "4                6.0            NaN  2020-01-01  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a474f6e8-d4b4-409d-aade-c6b51b504666",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_columns_mapping = {\n",
    " 'DATE': 'date',\n",
    " 'LATITUDE': 'latitude',\n",
    " 'LONGITUDE': 'longitude',\n",
    " 'DailyPrecipitation': 'daily_precipitation',\n",
    " 'HourlyPrecipitation': 'hourly_precipitation',\n",
    " 'DailyAverageWindSpeed': 'daily_average_wind_speed',\n",
    " 'HourlyWindSpeed': 'hourly_wind_speed',\n",
    " 'DailySnowfall': 'daily_snowfall'\n",
    "}\n",
    "weather_data.rename(columns=weather_columns_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "935261b7-ae23-427c-97ff-ea31aa4e44c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56098 entries, 0 to 56097\n",
      "Data columns (total 10 columns):\n",
      " #   Column                           Non-Null Count  Dtype         \n",
      "---  ------                           --------------  -----         \n",
      " 0   date                             56098 non-null  datetime64[ns]\n",
      " 1   latitude                         56098 non-null  float64       \n",
      " 2   longitude                        56098 non-null  float64       \n",
      " 3   MonthlyTotalLiquidPrecipitation  52 non-null     object        \n",
      " 4   daily_precipitation              1755 non-null   object        \n",
      " 5   hourly_precipitation             56098 non-null  float64       \n",
      " 6   daily_average_wind_speed         1697 non-null   float64       \n",
      " 7   hourly_wind_speed                49660 non-null  float64       \n",
      " 8   daily_snowfall                   1750 non-null   object        \n",
      " 9   DATE_ONLY                        56098 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(5), object(4)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "weather_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a7dcb502-d1d1-447d-aa68-11bff0dc53b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>hourly_precipitation</th>\n",
       "      <th>daily_average_wind_speed</th>\n",
       "      <th>hourly_wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56098</td>\n",
       "      <td>5.609800e+04</td>\n",
       "      <td>5.609800e+04</td>\n",
       "      <td>56098.000000</td>\n",
       "      <td>1697.000000</td>\n",
       "      <td>49660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-05-29 21:14:19.618881024</td>\n",
       "      <td>4.077898e+01</td>\n",
       "      <td>-7.396925e+01</td>\n",
       "      <td>0.010511</td>\n",
       "      <td>5.000766</td>\n",
       "      <td>5.125453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 00:51:00</td>\n",
       "      <td>4.077898e+01</td>\n",
       "      <td>-7.396925e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-03-18 19:01:45</td>\n",
       "      <td>4.077898e+01</td>\n",
       "      <td>-7.396925e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-05-28 01:21:00</td>\n",
       "      <td>4.077898e+01</td>\n",
       "      <td>-7.396925e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-08-15 05:39:00</td>\n",
       "      <td>4.077898e+01</td>\n",
       "      <td>-7.396925e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-10-22 18:51:00</td>\n",
       "      <td>4.077898e+01</td>\n",
       "      <td>-7.396925e+01</td>\n",
       "      <td>3.470000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>2237.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.214267e-11</td>\n",
       "      <td>5.815134e-11</td>\n",
       "      <td>0.056783</td>\n",
       "      <td>2.339258</td>\n",
       "      <td>14.653212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                date      latitude     longitude  \\\n",
       "count                          56098  5.609800e+04  5.609800e+04   \n",
       "mean   2022-05-29 21:14:19.618881024  4.077898e+01 -7.396925e+01   \n",
       "min              2020-01-01 00:51:00  4.077898e+01 -7.396925e+01   \n",
       "25%              2021-03-18 19:01:45  4.077898e+01 -7.396925e+01   \n",
       "50%              2022-05-28 01:21:00  4.077898e+01 -7.396925e+01   \n",
       "75%              2023-08-15 05:39:00  4.077898e+01 -7.396925e+01   \n",
       "max              2024-10-22 18:51:00  4.077898e+01 -7.396925e+01   \n",
       "std                              NaN  4.214267e-11  5.815134e-11   \n",
       "\n",
       "       hourly_precipitation  daily_average_wind_speed  hourly_wind_speed  \n",
       "count          56098.000000               1697.000000       49660.000000  \n",
       "mean               0.010511                  5.000766           5.125453  \n",
       "min                0.000000                  0.600000           0.000000  \n",
       "25%                0.000000                  3.200000           3.000000  \n",
       "50%                0.000000                  4.600000           5.000000  \n",
       "75%                0.000000                  6.300000           7.000000  \n",
       "max                3.470000                 14.200000        2237.000000  \n",
       "std                0.056783                  2.339258          14.653212  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "065190f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create daily_weather DataFrame\n",
    "daily_weather_data = weather_data[[\n",
    "    'date', 'latitude', 'longitude', 'daily_precipitation', \n",
    "    'daily_average_wind_speed', 'daily_snowfall'\n",
    "]].rename(columns={\n",
    "    'daily_average_wind_speed': 'daily_wind_speed'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bf2193a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hourly_weather DataFrame\n",
    "hourly_weather_data = weather_data[[\n",
    "    'date', 'latitude', 'longitude', 'hourly_precipitation', \n",
    "    'hourly_wind_speed', 'daily_snowfall'\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8b2ab99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# this is our in-memory database, not stored on your hard drive\n",
    "connection = sqlite3.connect(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS daily_weather (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    date DATETIME,\n",
    "    latitude REAL,\n",
    "    longitude REAL,\n",
    "    daily_precipitation REAL,\n",
    "    daily_wind_speed REAL,\n",
    "    daily_snowfall REAL\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS hourly_weather (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    date DATETIME,\n",
    "    latitude REAL,\n",
    "    longitude REAL,\n",
    "    hourly_precipitation REAL,\n",
    "    hourly_wind_speed REAL,\n",
    "    daily_snowfall REAL,\n",
    "    daily_id INTEGER, \n",
    "    FOREIGN KEY (daily_id) REFERENCES daily_weather(id)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS taxi_trips (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    pickup_datetime DATETIME,\n",
    "    dropoff_datetime DATETIME,\n",
    "    trip_distance REAL,\n",
    "    rate_code_id INTEGER,\n",
    "    pickup_location_id INTEGER,\n",
    "    dropoff_location_id INTEGER,\n",
    "    base_passenger_fare REAL,\n",
    "    rush_hour_surcharge REAL,\n",
    "    mta_tax REAL,\n",
    "    tip_amount REAL,\n",
    "    tolls_amount REAL,\n",
    "    improvement_surcharge REAL,\n",
    "    total_amount REAL,\n",
    "    congestion_surcharge REAL,\n",
    "    airport_fee REAL\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# might not need request_datetime\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS uber_trips (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    request_datetime DATETIME,\n",
    "    pickup_datetime DATETIME,\n",
    "    dropoff_datetime DATETIME,\n",
    "    trip_distance REAL,\n",
    "    pickup_location_id INTEGER,\n",
    "    dropoff_location_id INTEGER,\n",
    "    base_passenger_fare REAL,\n",
    "    tip_amount REAL,\n",
    "    tolls_amount REAL,\n",
    "    black_car_fund_fee REAL,\n",
    "    total_amount REAL,\n",
    "    sales_tax REAL,\n",
    "    congestion_surcharge REAL,\n",
    "    airport_fee REAL\n",
    ");\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "498e5499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first create a connection - we'll create a new database \n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(f\"sqlite:///4501_Project.db\", echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-02 19:24:30,824 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-12-02 19:24:30,838 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE IF NOT EXISTS hourly_weather (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    date DATETIME,\n",
      "    latitude REAL,\n",
      "    longitude REAL,\n",
      "    hourly_precipitation REAL,\n",
      "    hourly_wind_speed REAL,\n",
      "    daily_snowfall REAL,\n",
      "    daily_id INTEGER, \n",
      "    FOREIGN KEY (daily_id) REFERENCES daily_weather(id)\n",
      ");\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS daily_weather (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    date DATETIME,\n",
      "    latitude REAL,\n",
      "    longitude REAL,\n",
      "    daily_precipitation REAL,\n",
      "    daily_wind_speed REAL,\n",
      "    daily_snowfall REAL\n",
      ");\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS taxi_trips (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    pickup_datetime DATETIME,\n",
      "    dropoff_datetime DATETIME,\n",
      "    trip_distance REAL,\n",
      "    rate_code_id INTEGER,\n",
      "    pickup_location_id INTEGER,\n",
      "    dropoff_location_id INTEGER,\n",
      "    base_passenger_fare REAL,\n",
      "    rush_hour_surcharge REAL,\n",
      "    mta_tax REAL,\n",
      "    tip_amount REAL,\n",
      "    tolls_amount REAL,\n",
      "    improvement_surcharge REAL,\n",
      "    total_amount REAL,\n",
      "    congestion_surcharge REAL,\n",
      "    airport_fee REAL\n",
      ");\n",
      "\n",
      "CREATE TABLE IF NOT EXISTS uber_trips (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    request_datetime DATETIME,\n",
      "    pickup_datetime DATETIME,\n",
      "    dropoff_datetime DATETIME,\n",
      "    trip_distance REAL,\n",
      "    pickup_location_id INTEGER,\n",
      "    dropoff_location_id INTEGER,\n",
      "    base_passenger_fare REAL,\n",
      "    tip_amount REAL,\n",
      "    tolls_amount REAL,\n",
      "    black_car_fund_fee REAL,\n",
      "    total_amount REAL,\n",
      "    sales_tax REAL, -- Corrected misplaced comma\n",
      "    congestion_surcharge REAL,\n",
      "    airport_fee REAL\n",
      ");\n",
      "\n",
      "2024-12-02 19:24:30,844 INFO sqlalchemy.engine.Engine [generated in 0.02223s] ()\n",
      "2024-12-02 19:24:30,864 INFO sqlalchemy.engine.Engine ROLLBACK\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "(sqlite3.ProgrammingError) You can only execute one statement at a time.\n[SQL: \nCREATE TABLE IF NOT EXISTS hourly_weather (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    date DATETIME,\n    latitude REAL,\n    longitude REAL,\n    hourly_precipitation REAL,\n    hourly_wind_speed REAL,\n    daily_snowfall REAL,\n    daily_id INTEGER, \n    FOREIGN KEY (daily_id) REFERENCES daily_weather(id)\n);\n\nCREATE TABLE IF NOT EXISTS daily_weather (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    date DATETIME,\n    latitude REAL,\n    longitude REAL,\n    daily_precipitation REAL,\n    daily_wind_speed REAL,\n    daily_snowfall REAL\n);\n\nCREATE TABLE IF NOT EXISTS taxi_trips (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    pickup_datetime DATETIME,\n    dropoff_datetime DATETIME,\n    trip_distance REAL,\n    rate_code_id INTEGER,\n    pickup_location_id INTEGER,\n    dropoff_location_id INTEGER,\n    base_passenger_fare REAL,\n    rush_hour_surcharge REAL,\n    mta_tax REAL,\n    tip_amount REAL,\n    tolls_amount REAL,\n    improvement_surcharge REAL,\n    total_amount REAL,\n    congestion_surcharge REAL,\n    airport_fee REAL\n);\n\nCREATE TABLE IF NOT EXISTS uber_trips (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    request_datetime DATETIME,\n    pickup_datetime DATETIME,\n    dropoff_datetime DATETIME,\n    trip_distance REAL,\n    pickup_location_id INTEGER,\n    dropoff_location_id INTEGER,\n    base_passenger_fare REAL,\n    tip_amount REAL,\n    tolls_amount REAL,\n    black_car_fund_fee REAL,\n    total_amount REAL,\n    sales_tax REAL, -- Corrected misplaced comma\n    congestion_surcharge REAL,\n    airport_fee REAL\n);\n]\n(Background on this error at: https://sqlalche.me/e/20/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1967\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_execute(\n\u001b[1;32m   1968\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1969\u001b[0m         )\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/default.py:924\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 924\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[0;31mProgrammingError\u001b[0m: You can only execute one statement at a time.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[178], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(DATABASE_SCHEMA_FILE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m schema_file:\n\u001b[1;32m      4\u001b[0m     schema \u001b[38;5;241m=\u001b[39m schema_file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m----> 5\u001b[0m     connection\u001b[38;5;241m.\u001b[39mexecute(db\u001b[38;5;241m.\u001b[39mtext(schema))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1418\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m meth(\n\u001b[1;32m   1419\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1420\u001b[0m         distilled_parameters,\n\u001b[1;32m   1421\u001b[0m         execution_options \u001b[38;5;129;01mor\u001b[39;00m NO_OPTIONS,\n\u001b[1;32m   1422\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:515\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\u001b[38;5;241m.\u001b[39m_execute_clauseelement(\n\u001b[1;32m    516\u001b[0m         \u001b[38;5;28mself\u001b[39m, distilled_params, execution_options\n\u001b[1;32m    517\u001b[0m     )\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1640\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1628\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1629\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[1;32m   1630\u001b[0m )\n\u001b[1;32m   1632\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1633\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[1;32m   1634\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1638\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1639\u001b[0m )\n\u001b[0;32m-> 1640\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_context(\n\u001b[1;32m   1641\u001b[0m     dialect,\n\u001b[1;32m   1642\u001b[0m     dialect\u001b[38;5;241m.\u001b[39mexecution_ctx_cls\u001b[38;5;241m.\u001b[39m_init_compiled,\n\u001b[1;32m   1643\u001b[0m     compiled_sql,\n\u001b[1;32m   1644\u001b[0m     distilled_parameters,\n\u001b[1;32m   1645\u001b[0m     execution_options,\n\u001b[1;32m   1646\u001b[0m     compiled_sql,\n\u001b[1;32m   1647\u001b[0m     distilled_parameters,\n\u001b[1;32m   1648\u001b[0m     elem,\n\u001b[1;32m   1649\u001b[0m     extracted_params,\n\u001b[1;32m   1650\u001b[0m     cache_hit\u001b[38;5;241m=\u001b[39mcache_hit,\n\u001b[1;32m   1651\u001b[0m )\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[1;32m   1654\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1655\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1659\u001b[0m         ret,\n\u001b[1;32m   1660\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(dialect, context)\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_single_context(\n\u001b[1;32m   1847\u001b[0m         dialect, context, statement, parameters\n\u001b[1;32m   1848\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1983\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1986\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception(\n\u001b[1;32m   1987\u001b[0m         e, str_statement, effective_parameters, cursor, context\n\u001b[1;32m   1988\u001b[0m     )\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2353\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2351\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2352\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2353\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2354\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2355\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1965\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1967\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_execute(\n\u001b[1;32m   1968\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1969\u001b[0m         )\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1972\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1973\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1974\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1978\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[1;32m   1979\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/default.py:924\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 924\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[0;31mProgrammingError\u001b[0m: (sqlite3.ProgrammingError) You can only execute one statement at a time.\n[SQL: \nCREATE TABLE IF NOT EXISTS hourly_weather (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    date DATETIME,\n    latitude REAL,\n    longitude REAL,\n    hourly_precipitation REAL,\n    hourly_wind_speed REAL,\n    daily_snowfall REAL,\n    daily_id INTEGER, \n    FOREIGN KEY (daily_id) REFERENCES daily_weather(id)\n);\n\nCREATE TABLE IF NOT EXISTS daily_weather (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    date DATETIME,\n    latitude REAL,\n    longitude REAL,\n    daily_precipitation REAL,\n    daily_wind_speed REAL,\n    daily_snowfall REAL\n);\n\nCREATE TABLE IF NOT EXISTS taxi_trips (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    pickup_datetime DATETIME,\n    dropoff_datetime DATETIME,\n    trip_distance REAL,\n    rate_code_id INTEGER,\n    pickup_location_id INTEGER,\n    dropoff_location_id INTEGER,\n    base_passenger_fare REAL,\n    rush_hour_surcharge REAL,\n    mta_tax REAL,\n    tip_amount REAL,\n    tolls_amount REAL,\n    improvement_surcharge REAL,\n    total_amount REAL,\n    congestion_surcharge REAL,\n    airport_fee REAL\n);\n\nCREATE TABLE IF NOT EXISTS uber_trips (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    request_datetime DATETIME,\n    pickup_datetime DATETIME,\n    dropoff_datetime DATETIME,\n    trip_distance REAL,\n    pickup_location_id INTEGER,\n    dropoff_location_id INTEGER,\n    base_passenger_fare REAL,\n    tip_amount REAL,\n    tolls_amount REAL,\n    black_car_fund_fee REAL,\n    total_amount REAL,\n    sales_tax REAL, -- Corrected misplaced comma\n    congestion_surcharge REAL,\n    airport_fee REAL\n);\n]\n(Background on this error at: https://sqlalche.me/e/20/f405)"
     ]
    }
   ],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    with open(DATABASE_SCHEMA_FILE, 'r') as schema_file:\n",
    "        schema = schema_file.read()\n",
    "        connection.execute(db.text(schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "08085153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-02 19:24:34,122 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-12-02 19:24:34,133 INFO sqlalchemy.engine.Engine CREATE TABLE IF NOT EXISTS hourly_weather (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    date DATETIME,\n",
      "    latitude REAL,\n",
      "    longitude REAL,\n",
      "    hourly_precipitation REAL,\n",
      "    hourly_wind_speed REAL,\n",
      "    daily_snowfall REAL,\n",
      "    daily_id INTEGER, \n",
      "    FOREIGN KEY (daily_id) REFERENCES daily_weather(id)\n",
      ")\n",
      "2024-12-02 19:24:34,138 INFO sqlalchemy.engine.Engine [generated in 0.01897s] ()\n",
      "Executed: CREATE TABLE IF NOT EXISTS hourly_weather (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    date DATETIME,\n",
      "    latitude REAL,\n",
      "    longitude REAL,\n",
      "    hourly_precipitation REAL,\n",
      "    hourly_wind_speed REAL,\n",
      "    daily_snowfall REAL,\n",
      "    daily_id INTEGER, \n",
      "    FOREIGN KEY (daily_id) REFERENCES daily_weather(id)\n",
      ")\n",
      "2024-12-02 19:24:34,142 INFO sqlalchemy.engine.Engine CREATE TABLE IF NOT EXISTS daily_weather (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    date DATETIME,\n",
      "    latitude REAL,\n",
      "    longitude REAL,\n",
      "    daily_precipitation REAL,\n",
      "    daily_wind_speed REAL,\n",
      "    daily_snowfall REAL\n",
      ")\n",
      "2024-12-02 19:24:34,144 INFO sqlalchemy.engine.Engine [generated in 0.00115s] ()\n",
      "Executed: CREATE TABLE IF NOT EXISTS daily_weather (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    date DATETIME,\n",
      "    latitude REAL,\n",
      "    longitude REAL,\n",
      "    daily_precipitation REAL,\n",
      "    daily_wind_speed REAL,\n",
      "    daily_snowfall REAL\n",
      ")\n",
      "2024-12-02 19:24:34,146 INFO sqlalchemy.engine.Engine CREATE TABLE IF NOT EXISTS taxi_trips (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    pickup_datetime DATETIME,\n",
      "    dropoff_datetime DATETIME,\n",
      "    trip_distance REAL,\n",
      "    rate_code_id INTEGER,\n",
      "    pickup_location_id INTEGER,\n",
      "    dropoff_location_id INTEGER,\n",
      "    base_passenger_fare REAL,\n",
      "    rush_hour_surcharge REAL,\n",
      "    mta_tax REAL,\n",
      "    tip_amount REAL,\n",
      "    tolls_amount REAL,\n",
      "    improvement_surcharge REAL,\n",
      "    total_amount REAL,\n",
      "    congestion_surcharge REAL,\n",
      "    airport_fee REAL\n",
      ")\n",
      "2024-12-02 19:24:34,148 INFO sqlalchemy.engine.Engine [generated in 0.00150s] ()\n",
      "Executed: CREATE TABLE IF NOT EXISTS taxi_trips (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    pickup_datetime DATETIME,\n",
      "    dropoff_datetime DATETIME,\n",
      "    trip_distance REAL,\n",
      "    rate_code_id INTEGER,\n",
      "    pickup_location_id INTEGER,\n",
      "    dropoff_location_id INTEGER,\n",
      "    base_passenger_fare REAL,\n",
      "    rush_hour_surcharge REAL,\n",
      "    mta_tax REAL,\n",
      "    tip_amount REAL,\n",
      "    tolls_amount REAL,\n",
      "    improvement_surcharge REAL,\n",
      "    total_amount REAL,\n",
      "    congestion_surcharge REAL,\n",
      "    airport_fee REAL\n",
      ")\n",
      "2024-12-02 19:24:34,150 INFO sqlalchemy.engine.Engine CREATE TABLE IF NOT EXISTS uber_trips (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    request_datetime DATETIME,\n",
      "    pickup_datetime DATETIME,\n",
      "    dropoff_datetime DATETIME,\n",
      "    trip_distance REAL,\n",
      "    pickup_location_id INTEGER,\n",
      "    dropoff_location_id INTEGER,\n",
      "    base_passenger_fare REAL,\n",
      "    tip_amount REAL,\n",
      "    tolls_amount REAL,\n",
      "    black_car_fund_fee REAL,\n",
      "    total_amount REAL,\n",
      "    sales_tax REAL, -- Corrected misplaced comma\n",
      "    congestion_surcharge REAL,\n",
      "    airport_fee REAL\n",
      ")\n",
      "2024-12-02 19:24:34,152 INFO sqlalchemy.engine.Engine [generated in 0.00127s] ()\n",
      "Executed: CREATE TABLE IF NOT EXISTS uber_trips (\n",
      "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    request_datetime DATETIME,\n",
      "    pickup_datetime DATETIME,\n",
      "    dropoff_datetime DATETIME,\n",
      "    trip_distance REAL,\n",
      "    pickup_location_id INTEGER,\n",
      "    dropoff_location_id INTEGER,\n",
      "    base_passenger_fare REAL,\n",
      "    tip_amount REAL,\n",
      "    tolls_amount REAL,\n",
      "    black_car_fund_fee REAL,\n",
      "    total_amount REAL,\n",
      "    sales_tax REAL, -- Corrected misplaced comma\n",
      "    congestion_surcharge REAL,\n",
      "    airport_fee REAL\n",
      ")\n",
      "2024-12-02 19:24:34,154 INFO sqlalchemy.engine.Engine ROLLBACK\n"
     ]
    }
   ],
   "source": [
    "# create the tables with the schema files\n",
    "from sqlalchemy import text\n",
    "\n",
    "# Assuming `DATABASE_SCHEMA_FILE` contains your schema as a string\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "\n",
    "# Read the schema file\n",
    "with open(DATABASE_SCHEMA_FILE, \"r\") as schema_file:\n",
    "    schema = schema_file.read()\n",
    "\n",
    "# Split the schema into individual statements\n",
    "statements = schema.strip().split(\";\")\n",
    "statements = [stmt.strip() for stmt in statements if stmt.strip()]  # Remove empty statements\n",
    "\n",
    "\n",
    "# Execute each statement individually\n",
    "with engine.connect() as connection:\n",
    "    for statement in statements:\n",
    "        try:\n",
    "            connection.execute(text(statement))\n",
    "            print(f\"Executed: {statement}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing statement: {statement}\")\n",
    "            print(f\"Exception: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4866de4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-02 19:24:38,997 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-12-02 19:24:39,001 INFO sqlalchemy.engine.Engine SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite~_%' ESCAPE '~' ORDER BY name\n",
      "2024-12-02 19:24:39,004 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:24:39,012 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "Available tables: ['daily_weather', 'hourly_weather', 'taxi_trips', 'uber_trips']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "\n",
    "inspector = inspect(engine)\n",
    "tables = inspector.get_table_names()\n",
    "print(\"Available tables:\", tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "110cfd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-02 19:24:43,288 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-12-02 19:24:43,305 INFO sqlalchemy.engine.Engine PRAGMA main.table_xinfo(\"taxi_trips\")\n",
      "2024-12-02 19:24:43,357 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:24:43,370 INFO sqlalchemy.engine.Engine ROLLBACK\n",
      "Column: id, Type: INTEGER\n",
      "Column: pickup_datetime, Type: DATETIME\n",
      "Column: dropoff_datetime, Type: DATETIME\n",
      "Column: trip_distance, Type: REAL\n",
      "Column: rate_code_id, Type: INTEGER\n",
      "Column: pickup_location_id, Type: INTEGER\n",
      "Column: dropoff_location_id, Type: INTEGER\n",
      "Column: base_passenger_fare, Type: REAL\n",
      "Column: rush_hour_surcharge, Type: REAL\n",
      "Column: mta_tax, Type: REAL\n",
      "Column: tip_amount, Type: REAL\n",
      "Column: tolls_amount, Type: REAL\n",
      "Column: improvement_surcharge, Type: REAL\n",
      "Column: total_amount, Type: REAL\n",
      "Column: congestion_surcharge, Type: REAL\n",
      "Column: airport_fee, Type: REAL\n"
     ]
    }
   ],
   "source": [
    "columns = inspector.get_columns('taxi_trips')\n",
    "for column in columns:\n",
    "    print(f\"Column: {column['name']}, Type: {column['type']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "956de52a-169e-456d-be1f-4ea57b4104d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-02 19:48:46,536 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-12-02 19:48:46,552 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"taxi_trips\")\n",
      "2024-12-02 19:48:46,603 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:46,606 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"taxi_trips\")\n",
      "2024-12-02 19:48:46,607 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:46,611 INFO sqlalchemy.engine.Engine SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite~_%' ESCAPE '~' ORDER BY name\n",
      "2024-12-02 19:48:46,612 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:46,622 INFO sqlalchemy.engine.Engine SELECT name FROM sqlite_master WHERE type='view' AND name NOT LIKE 'sqlite~_%' ESCAPE '~' ORDER BY name\n",
      "2024-12-02 19:48:46,627 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:46,630 INFO sqlalchemy.engine.Engine PRAGMA main.table_xinfo(\"taxi_trips\")\n",
      "2024-12-02 19:48:46,631 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:46,633 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2024-12-02 19:48:46,636 INFO sqlalchemy.engine.Engine [raw sql] ('taxi_trips',)\n",
      "2024-12-02 19:48:46,638 INFO sqlalchemy.engine.Engine PRAGMA main.foreign_key_list(\"taxi_trips\")\n",
      "2024-12-02 19:48:46,640 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:46,642 INFO sqlalchemy.engine.Engine PRAGMA temp.foreign_key_list(\"taxi_trips\")\n",
      "2024-12-02 19:48:46,643 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:46,645 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2024-12-02 19:48:46,647 INFO sqlalchemy.engine.Engine [raw sql] ('taxi_trips',)\n",
      "2024-12-02 19:48:46,648 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"taxi_trips\")\n",
      "2024-12-02 19:48:46,649 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:46,651 INFO sqlalchemy.engine.Engine PRAGMA temp.index_list(\"taxi_trips\")\n",
      "2024-12-02 19:48:46,652 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:46,655 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"taxi_trips\")\n",
      "2024-12-02 19:48:46,656 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:46,658 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"taxi_trips\")\n",
      "2024-12-02 19:48:46,660 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:46,661 INFO sqlalchemy.engine.Engine PRAGMA temp.index_list(\"taxi_trips\")\n",
      "2024-12-02 19:48:46,663 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:46,665 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"taxi_trips\")\n",
      "2024-12-02 19:48:46,666 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:46,671 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2024-12-02 19:48:46,672 INFO sqlalchemy.engine.Engine [raw sql] ('taxi_trips',)\n",
      "2024-12-02 19:48:46,679 INFO sqlalchemy.engine.Engine \n",
      "DROP TABLE taxi_trips\n",
      "2024-12-02 19:48:46,684 INFO sqlalchemy.engine.Engine [no key 0.00506s] ()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-02 19:48:46,746 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE taxi_trips (\n",
      "\tpickup_datetime DATETIME, \n",
      "\tdropoff_datetime DATETIME, \n",
      "\ttrip_distance FLOAT, \n",
      "\trate_code_id FLOAT, \n",
      "\tpickup_location_id BIGINT, \n",
      "\tdropoff_location_id BIGINT, \n",
      "\tbase_passenger_fare FLOAT, \n",
      "\trush_hour_surcharge FLOAT, \n",
      "\tmta_tax FLOAT, \n",
      "\ttip_amount FLOAT, \n",
      "\ttolls_amount FLOAT, \n",
      "\timprovement_surcharge FLOAT, \n",
      "\ttotal_amount FLOAT, \n",
      "\tcongestion_surcharge FLOAT, \n",
      "\tairport_fee FLOAT, \n",
      "\tzone TEXT, \n",
      "\tlocation_id INTEGER, \n",
      "\tcentroid_lat FLOAT, \n",
      "\tcentroid_lon FLOAT\n",
      ")\n",
      "\n",
      "\n",
      "2024-12-02 19:48:46,960 INFO sqlalchemy.engine.Engine [no key 0.20656s] ()\n",
      "2024-12-02 19:48:49,237 INFO sqlalchemy.engine.Engine INSERT INTO taxi_trips (pickup_datetime, dropoff_datetime, trip_distance, rate_code_id, pickup_location_id, dropoff_location_id, base_passenger_fare, rush_hour_surcharge, mta_tax, tip_amount, tolls_amount, improvement_surcharge, total_amount, congestion_surcharge, airport_fee, zone, location_id, centroid_lat, centroid_lon) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
      "2024-12-02 19:48:49,266 INFO sqlalchemy.engine.Engine [generated in 1.67030s] [('2023-06-28 08:27:09.000000', '2023-06-28 09:21:52.000000', 10.22, 1.0, 138, 144, 57.6, 5.0, 0.5, 17.09, 0.0, 1.0, 85.44, 2.5, None, 'LaGuardia Airport', 138, 40.774375005218495, -73.87362858929275), ('2023-06-13 22:05:38.000000', '2023-06-13 22:10:48.000000', 0.8, 1.0, 263, 237, 7.2, 3.5, 0.5, 0.0, 0.0, 1.0, 12.2, 2.5, None, 'Yorkville West', 263, 40.77876526484269, -73.95100966112463), ('2023-06-09 10:25:49.000000', '2023-06-09 10:41:51.000000', 1.62, 1.0, 162, 236, 15.6, 0.0, 0.5, 2.0, 0.0, 1.0, 21.6, 2.5, None, 'Midtown East', 162, 40.75668705623963, -73.97235570252612), ('2023-06-28 15:56:14.000000', '2023-06-28 17:22:03.000000', 18.9, 3.0, 229, 1, 114.7, 0.0, 0.0, 27.65, 22.75, 1.0, 166.1, 0.0, None, 'Sutton Place/Turtle Bay North', 229, 40.7567283313704, -73.96514556779753), ('2023-06-22 07:12:42.000000', '2023-06-22 07:23:47.000000', 1.52, 1.0, 43, 74, 11.4, 0.0, 0.5, 1.94, 0.0, 1.0, 14.84, 0.0, None, 'Central Park', 43, 40.7824775466351, -73.96555333253924), ('2023-06-20 05:41:32.000000', '2023-06-20 05:52:27.000000', 2.41, 1.0, 170, 158, 13.5, 1.0, 0.5, 3.7, 0.0, 1.0, 22.2, 2.5, None, 'Murray Hill', 170, 40.7477452050439, -73.97849135821008), ('2023-06-05 08:27:56.000000', '2023-06-05 08:45:00.000000', 2.5, 1.0, 224, 161, 14.9, 2.5, 0.5, 0.0, 0.0, 1.0, 18.9, 2.5, None, 'Stuy Town/Peter Cooper Village', 224, 40.73182007341155, -73.9765974749919), ('2023-06-07 16:45:13.000000', '2023-06-07 17:01:53.000000', 2.0, 1.0, 161, 262, 16.3, 2.5, 0.5, 4.56, 0.0, 1.0, 27.36, 2.5, None, 'Midtown Center', 161, 40.7580274612078, -73.97769768309725)  ... displaying 10 of 20826 total bound parameter sets ...  ('2023-03-08 12:06:06.000000', '2023-03-08 12:07:37.000000', 0.23, 1.0, 141, 141, 3.7, 0.0, 0.5, 1.54, 0.0, 1.0, 9.24, 2.5, None, 'Lenox Hill West', 141, 40.766947617410686, -73.95963451700108), ('2023-03-19 23:34:47.000000', '2023-03-19 23:56:15.000000', 10.63, 1.0, 138, 231, 42.9, 6.0, 0.5, 8.12, 0.0, 1.0, 62.27, 2.5, None, 'LaGuardia Airport', 138, 40.774375005218495, -73.87362858929275)]\n",
      "2024-12-02 19:48:49,856 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2024-12-02 19:48:49,868 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-12-02 19:48:49,877 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"uber_trips\")\n",
      "2024-12-02 19:48:49,882 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:49,886 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"uber_trips\")\n",
      "2024-12-02 19:48:49,891 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:49,899 INFO sqlalchemy.engine.Engine SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite~_%' ESCAPE '~' ORDER BY name\n",
      "2024-12-02 19:48:49,904 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:49,909 INFO sqlalchemy.engine.Engine SELECT name FROM sqlite_master WHERE type='view' AND name NOT LIKE 'sqlite~_%' ESCAPE '~' ORDER BY name\n",
      "2024-12-02 19:48:49,926 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:49,937 INFO sqlalchemy.engine.Engine PRAGMA main.table_xinfo(\"uber_trips\")\n",
      "2024-12-02 19:48:49,950 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:49,956 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2024-12-02 19:48:49,961 INFO sqlalchemy.engine.Engine [raw sql] ('uber_trips',)\n",
      "2024-12-02 19:48:49,967 INFO sqlalchemy.engine.Engine PRAGMA main.foreign_key_list(\"uber_trips\")\n",
      "2024-12-02 19:48:49,970 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:49,980 INFO sqlalchemy.engine.Engine PRAGMA temp.foreign_key_list(\"uber_trips\")\n",
      "2024-12-02 19:48:49,986 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:50,000 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2024-12-02 19:48:50,002 INFO sqlalchemy.engine.Engine [raw sql] ('uber_trips',)\n",
      "2024-12-02 19:48:50,012 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"uber_trips\")\n",
      "2024-12-02 19:48:50,018 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:50,020 INFO sqlalchemy.engine.Engine PRAGMA temp.index_list(\"uber_trips\")\n",
      "2024-12-02 19:48:50,027 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:50,031 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"uber_trips\")\n",
      "2024-12-02 19:48:50,036 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:50,037 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"uber_trips\")\n",
      "2024-12-02 19:48:50,042 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:50,047 INFO sqlalchemy.engine.Engine PRAGMA temp.index_list(\"uber_trips\")\n",
      "2024-12-02 19:48:50,052 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:50,058 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"uber_trips\")\n",
      "2024-12-02 19:48:50,065 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:50,067 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2024-12-02 19:48:50,071 INFO sqlalchemy.engine.Engine [raw sql] ('uber_trips',)\n",
      "2024-12-02 19:48:50,080 INFO sqlalchemy.engine.Engine \n",
      "DROP TABLE uber_trips\n",
      "2024-12-02 19:48:50,083 INFO sqlalchemy.engine.Engine [no key 0.00264s] ()\n",
      "2024-12-02 19:48:50,172 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE uber_trips (\n",
      "\thvfhs_license_num TEXT, \n",
      "\trequest_datetime DATETIME, \n",
      "\tpickup_datetime DATETIME, \n",
      "\tdropoff_datetime DATETIME, \n",
      "\tpickup_location_id BIGINT, \n",
      "\tdropoff_location_id BIGINT, \n",
      "\ttrip_distance FLOAT, \n",
      "\tbase_passenger_fare FLOAT, \n",
      "\ttolls_amount FLOAT, \n",
      "\tblack_car_fund_fee FLOAT, \n",
      "\tsales_tax FLOAT, \n",
      "\tcongestion_surcharge FLOAT, \n",
      "\tairport_fee FLOAT, \n",
      "\ttip_amount FLOAT, \n",
      "\tzone TEXT, \n",
      "\tlocation_id INTEGER, \n",
      "\tcentroid_lat FLOAT, \n",
      "\tcentroid_lon FLOAT\n",
      ")\n",
      "\n",
      "\n",
      "2024-12-02 19:48:50,178 INFO sqlalchemy.engine.Engine [no key 0.00561s] ()\n",
      "2024-12-02 19:48:52,385 INFO sqlalchemy.engine.Engine INSERT INTO uber_trips (hvfhs_license_num, request_datetime, pickup_datetime, dropoff_datetime, pickup_location_id, dropoff_location_id, trip_distance, base_passenger_fare, tolls_amount, black_car_fund_fee, sales_tax, congestion_surcharge, airport_fee, tip_amount, zone, location_id, centroid_lat, centroid_lon) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
      "2024-12-02 19:48:52,386 INFO sqlalchemy.engine.Engine [generated in 1.86749s] [('HV0003', '2021-03-19 08:07:07.000000', '2021-03-19 08:11:50.000000', '2021-03-19 08:20:59.000000', 97, 231, 2.52, 12.58, 0.0, 0.39, 1.14, 2.75, None, 0.0, 'Fort Greene', 97, 40.6907863176237, -73.97488199899603), ('HV0003', '2021-03-01 22:02:07.000000', '2021-03-01 22:08:28.000000', '2021-03-01 22:20:19.000000', 247, 20, 2.41, 11.94, 0.0, 0.36, 1.06, 0.0, None, 0.0, 'West Concourse', 247, 40.828987694092085, -73.92440854980768), ('HV0003', '2021-03-13 05:42:59.000000', '2021-03-13 05:48:40.000000', '2021-03-13 05:55:36.000000', 18, 247, 2.21, 15.25, 0.0, 0.46, 1.35, 0.0, None, 0.0, 'Bedford Park', 18, 40.86768193078259, -73.89018314457128), ('HV0003', '2021-03-12 20:58:30.000000', '2021-03-12 21:02:02.000000', '2021-03-12 21:25:13.000000', 211, 229, 3.85, 21.51, 0.0, 0.65, 1.91, 2.75, None, 0.0, 'SoHo', 211, 40.723887614774306, -74.0015373573135), ('HV0003', '2021-03-31 08:42:41.000000', '2021-03-31 08:49:53.000000', '2021-03-31 09:56:02.000000', 74, 45, 18.96, 71.31, 6.12, 2.33, 6.89, 2.75, 0.0, 0.0, 'East Harlem North', 74, 40.80116891085427, -73.93734541088787), ('HV0003', '2021-03-17 14:45:07.000000', '2021-03-17 14:48:30.000000', '2021-03-17 15:10:50.000000', 76, 61, 3.28, 18.13, 0.0, 0.54, 1.61, 0.0, None, 0.0, 'East New York', 76, 40.66093459851305, -73.87682073091827), ('HV0003', '2021-03-07 00:58:17.000000', '2021-03-07 01:02:01.000000', '2021-03-07 01:13:40.000000', 228, 25, 2.28, 12.11, 0.0, 0.36, 1.07, 0.0, None, 0.0, 'Sunset Park West', 228, 40.652354316327425, -74.01127116085716), ('HV0003', '2021-03-10 10:10:57.000000', '2021-03-10 10:18:55.000000', '2021-03-10 10:22:06.000000', 117, 117, 0.05, 6.47, 0.0, 0.19, 0.57, 0.0, None, 0.0, 'Hammels/Arverne', 117, 40.59405805608838, -73.78962241188152)  ... displaying 10 of 20678 total bound parameter sets ...  ('HV0003', '2024-07-23 11:33:27.000000', '2024-07-23 11:39:13.000000', '2024-07-23 11:52:06.000000', 42, 244, 2.06, 9.83, 0.0, 0.27, 0.87, 0.0, 0.0, 0.0, 'Central Harlem North', 42, 40.81825733537333, -73.94077146485533), ('HV0003', '2024-07-05 22:02:36.000000', '2024-07-05 22:05:49.000000', '2024-07-05 22:11:36.000000', 127, 243, 0.79, 8.94, 0.0, 0.25, 0.79, 0.0, 0.0, 0.0, 'Inwood', 127, 40.86607453332792, -73.91930805641887)]\n",
      "2024-12-02 19:48:52,604 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2024-12-02 19:48:52,647 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-12-02 19:48:52,695 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"hourly_weather\")\n",
      "2024-12-02 19:48:52,704 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:52,720 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"hourly_weather\")\n",
      "2024-12-02 19:48:52,727 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:52,734 INFO sqlalchemy.engine.Engine SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite~_%' ESCAPE '~' ORDER BY name\n",
      "2024-12-02 19:48:52,737 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:52,748 INFO sqlalchemy.engine.Engine SELECT name FROM sqlite_master WHERE type='view' AND name NOT LIKE 'sqlite~_%' ESCAPE '~' ORDER BY name\n",
      "2024-12-02 19:48:52,755 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:52,765 INFO sqlalchemy.engine.Engine PRAGMA main.table_xinfo(\"hourly_weather\")\n",
      "2024-12-02 19:48:52,770 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:52,779 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2024-12-02 19:48:52,782 INFO sqlalchemy.engine.Engine [raw sql] ('hourly_weather',)\n",
      "2024-12-02 19:48:52,796 INFO sqlalchemy.engine.Engine PRAGMA main.foreign_key_list(\"hourly_weather\")\n",
      "2024-12-02 19:48:52,817 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:52,836 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2024-12-02 19:48:52,845 INFO sqlalchemy.engine.Engine [raw sql] ('hourly_weather',)\n",
      "2024-12-02 19:48:52,860 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"hourly_weather\")\n",
      "2024-12-02 19:48:52,862 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:52,865 INFO sqlalchemy.engine.Engine PRAGMA temp.index_list(\"hourly_weather\")\n",
      "2024-12-02 19:48:52,868 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:52,871 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"hourly_weather\")\n",
      "2024-12-02 19:48:52,873 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:52,879 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"hourly_weather\")\n",
      "2024-12-02 19:48:52,881 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:52,884 INFO sqlalchemy.engine.Engine PRAGMA temp.index_list(\"hourly_weather\")\n",
      "2024-12-02 19:48:52,886 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:52,892 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"hourly_weather\")\n",
      "2024-12-02 19:48:52,894 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:52,905 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2024-12-02 19:48:52,909 INFO sqlalchemy.engine.Engine [raw sql] ('hourly_weather',)\n",
      "2024-12-02 19:48:52,916 INFO sqlalchemy.engine.Engine PRAGMA main.table_xinfo(\"daily_weather\")\n",
      "2024-12-02 19:48:52,922 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:53,032 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2024-12-02 19:48:53,037 INFO sqlalchemy.engine.Engine [raw sql] ('daily_weather',)\n",
      "2024-12-02 19:48:53,047 INFO sqlalchemy.engine.Engine PRAGMA main.foreign_key_list(\"daily_weather\")\n",
      "2024-12-02 19:48:53,049 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:53,051 INFO sqlalchemy.engine.Engine PRAGMA temp.foreign_key_list(\"daily_weather\")\n",
      "2024-12-02 19:48:53,053 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:53,062 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2024-12-02 19:48:53,066 INFO sqlalchemy.engine.Engine [raw sql] ('daily_weather',)\n",
      "2024-12-02 19:48:53,076 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"daily_weather\")\n",
      "2024-12-02 19:48:53,081 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:53,084 INFO sqlalchemy.engine.Engine PRAGMA temp.index_list(\"daily_weather\")\n",
      "2024-12-02 19:48:53,085 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:53,087 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"daily_weather\")\n",
      "2024-12-02 19:48:53,090 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:53,096 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"daily_weather\")\n",
      "2024-12-02 19:48:53,103 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:53,106 INFO sqlalchemy.engine.Engine PRAGMA temp.index_list(\"daily_weather\")\n",
      "2024-12-02 19:48:53,116 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:53,123 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"daily_weather\")\n",
      "2024-12-02 19:48:53,128 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:53,136 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2024-12-02 19:48:53,139 INFO sqlalchemy.engine.Engine [raw sql] ('daily_weather',)\n",
      "2024-12-02 19:48:53,153 INFO sqlalchemy.engine.Engine \n",
      "DROP TABLE hourly_weather\n",
      "2024-12-02 19:48:53,157 INFO sqlalchemy.engine.Engine [no key 0.00417s] ()\n",
      "2024-12-02 19:48:53,196 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE hourly_weather (\n",
      "\tdate DATETIME, \n",
      "\tlatitude FLOAT, \n",
      "\tlongitude FLOAT, \n",
      "\thourly_precipitation FLOAT, \n",
      "\thourly_wind_speed FLOAT, \n",
      "\tdaily_snowfall TEXT\n",
      ")\n",
      "\n",
      "\n",
      "2024-12-02 19:48:53,200 INFO sqlalchemy.engine.Engine [no key 0.00461s] ()\n",
      "2024-12-02 19:48:57,057 INFO sqlalchemy.engine.Engine INSERT INTO hourly_weather (date, latitude, longitude, hourly_precipitation, hourly_wind_speed, daily_snowfall) VALUES (?, ?, ?, ?, ?, ?)\n",
      "2024-12-02 19:48:57,061 INFO sqlalchemy.engine.Engine [generated in 3.11924s] [('2020-01-01 00:51:00.000000', 40.77898, -73.96925, 0.0, 8.0, None), ('2020-01-01 01:51:00.000000', 40.77898, -73.96925, 0.0, 8.0, None), ('2020-01-01 02:51:00.000000', 40.77898, -73.96925, 0.0, 14.0, None), ('2020-01-01 03:51:00.000000', 40.77898, -73.96925, 0.0, 11.0, None), ('2020-01-01 04:51:00.000000', 40.77898, -73.96925, 0.0, 6.0, None), ('2020-01-01 05:51:00.000000', 40.77898, -73.96925, 0.0, 3.0, None), ('2020-01-01 06:51:00.000000', 40.77898, -73.96925, 0.0, 8.0, None), ('2020-01-01 07:51:00.000000', 40.77898, -73.96925, 0.0, 8.0, None)  ... displaying 10 of 56098 total bound parameter sets ...  ('2022-12-31 23:59:00.000000', 40.77898, -73.96925, 0.0, None, '0.0'), ('2022-12-31 23:59:00.000000', 40.77898, -73.96925, 0.0, None, None)]\n",
      "2024-12-02 19:48:57,804 INFO sqlalchemy.engine.Engine COMMIT\n",
      "2024-12-02 19:48:57,815 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-12-02 19:48:57,821 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"daily_weather\")\n",
      "2024-12-02 19:48:57,822 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:57,827 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"daily_weather\")\n",
      "2024-12-02 19:48:57,832 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:57,835 INFO sqlalchemy.engine.Engine SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite~_%' ESCAPE '~' ORDER BY name\n",
      "2024-12-02 19:48:57,838 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:57,840 INFO sqlalchemy.engine.Engine SELECT name FROM sqlite_master WHERE type='view' AND name NOT LIKE 'sqlite~_%' ESCAPE '~' ORDER BY name\n",
      "2024-12-02 19:48:57,842 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:57,849 INFO sqlalchemy.engine.Engine PRAGMA main.table_xinfo(\"daily_weather\")\n",
      "2024-12-02 19:48:57,850 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:57,853 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2024-12-02 19:48:57,855 INFO sqlalchemy.engine.Engine [raw sql] ('daily_weather',)\n",
      "2024-12-02 19:48:57,862 INFO sqlalchemy.engine.Engine PRAGMA main.foreign_key_list(\"daily_weather\")\n",
      "2024-12-02 19:48:57,863 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:57,865 INFO sqlalchemy.engine.Engine PRAGMA temp.foreign_key_list(\"daily_weather\")\n",
      "2024-12-02 19:48:57,868 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:57,873 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2024-12-02 19:48:57,875 INFO sqlalchemy.engine.Engine [raw sql] ('daily_weather',)\n",
      "2024-12-02 19:48:57,880 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"daily_weather\")\n",
      "2024-12-02 19:48:57,884 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:57,886 INFO sqlalchemy.engine.Engine PRAGMA temp.index_list(\"daily_weather\")\n",
      "2024-12-02 19:48:57,888 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:57,890 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"daily_weather\")\n",
      "2024-12-02 19:48:57,899 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:57,905 INFO sqlalchemy.engine.Engine PRAGMA main.index_list(\"daily_weather\")\n",
      "2024-12-02 19:48:57,916 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:57,919 INFO sqlalchemy.engine.Engine PRAGMA temp.index_list(\"daily_weather\")\n",
      "2024-12-02 19:48:57,923 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:57,928 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"daily_weather\")\n",
      "2024-12-02 19:48:57,932 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-12-02 19:48:57,936 INFO sqlalchemy.engine.Engine SELECT sql FROM  (SELECT * FROM sqlite_master UNION ALL   SELECT * FROM sqlite_temp_master) WHERE name = ? AND type in ('table', 'view')\n",
      "2024-12-02 19:48:57,938 INFO sqlalchemy.engine.Engine [raw sql] ('daily_weather',)\n",
      "2024-12-02 19:48:57,947 INFO sqlalchemy.engine.Engine \n",
      "DROP TABLE daily_weather\n",
      "2024-12-02 19:48:57,948 INFO sqlalchemy.engine.Engine [no key 0.00110s] ()\n",
      "2024-12-02 19:48:57,965 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE daily_weather (\n",
      "\tdate DATETIME, \n",
      "\tlatitude FLOAT, \n",
      "\tlongitude FLOAT, \n",
      "\tdaily_precipitation TEXT, \n",
      "\tdaily_wind_speed FLOAT, \n",
      "\tdaily_snowfall TEXT\n",
      ")\n",
      "\n",
      "\n",
      "2024-12-02 19:48:57,967 INFO sqlalchemy.engine.Engine [no key 0.00148s] ()\n",
      "2024-12-02 19:49:01,396 INFO sqlalchemy.engine.Engine INSERT INTO daily_weather (date, latitude, longitude, daily_precipitation, daily_wind_speed, daily_snowfall) VALUES (?, ?, ?, ?, ?, ?)\n",
      "2024-12-02 19:49:01,398 INFO sqlalchemy.engine.Engine [generated in 3.02705s] [('2020-01-01 00:51:00.000000', 40.77898, -73.96925, None, None, None), ('2020-01-01 01:51:00.000000', 40.77898, -73.96925, None, None, None), ('2020-01-01 02:51:00.000000', 40.77898, -73.96925, None, None, None), ('2020-01-01 03:51:00.000000', 40.77898, -73.96925, None, None, None), ('2020-01-01 04:51:00.000000', 40.77898, -73.96925, None, None, None), ('2020-01-01 05:51:00.000000', 40.77898, -73.96925, None, None, None), ('2020-01-01 06:51:00.000000', 40.77898, -73.96925, None, None, None), ('2020-01-01 07:51:00.000000', 40.77898, -73.96925, None, None, None)  ... displaying 10 of 56098 total bound parameter sets ...  ('2022-12-31 23:59:00.000000', 40.77898, -73.96925, '0.28', 1.8, '0.0'), ('2022-12-31 23:59:00.000000', 40.77898, -73.96925, None, None, None)]\n",
      "2024-12-02 19:49:01,734 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56098"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final_taxi_data, uber_data, hourly_weather_data, daily_weather_data\n",
    "\n",
    "# Load sampled trip data into each database\n",
    "final_taxi_data.to_sql('taxi_trips', con=engine, if_exists='replace', index=False)\n",
    "final_uber_data.to_sql('uber_trips', con=engine, if_exists='replace', index=False)\n",
    "hourly_weather_data.to_sql('hourly_weather', con=engine, if_exists='replace', index=False)\n",
    "daily_weather_data.to_sql('daily_weather', con=engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(table_to_df_dict):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_data,\n",
    "    \"daily_weather\": daily_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74004f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(map_table_name_to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = \"\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "TODO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute query either via sqlalchemy\n",
    "with engine.connect() as con:\n",
    "    results = con.execute(db.text(QUERY_1)).fetchall()\n",
    "results\n",
    "\n",
    "# or via pandas\n",
    "pd.read_sql(QUERY_1, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_1(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
