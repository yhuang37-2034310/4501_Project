{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1VERPjEZcC1XSs4-02aM-DbkNr_yaJVbFjLJxaYQswqA/edit#)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "10434bfd-2214-4f09-bd1e-5d342f60c17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /opt/anaconda3/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (1.26.4)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (0.10.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (23.2)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (2.2.2)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (3.6.1)\n",
      "Requirement already satisfied: shapely>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (2.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from pyogrio>=0.7.2->geopandas) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "\n",
    "import os\n",
    "\n",
    "import bs4\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import geopandas as gpd\n",
    "import math\n",
    "import glob\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import sqlalchemy as db\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants you might need; some have been added for you, and \n",
    "# some you need to fill in\n",
    "\n",
    "TLC_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "PARQUET_FILES = \"parquet_files\"\n",
    "TAXI_ZONES_DIR = \"taxi_zones\"\n",
    "TAXI_ZONES_SHAPEFILE = f\"{TAXI_ZONES_DIR}/taxi_zones.shp\"\n",
    "WEATHER_CSV_DIR = \"weather_data\"\n",
    "\n",
    "#CRS = 4326  # coordinate reference system\n",
    "\n",
    "# (lat, lon)\n",
    "#NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "LGA_BOX_COORDS = ((40.763589, -73.891745), (40.778865, -73.854838))\n",
    "JFK_BOX_COORDS = ((40.639263, -73.795642), (40.651376, -73.766264))\n",
    "EWR_BOX_COORDS = ((40.686794, -74.194028), (40.699680, -74.165205))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6601633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "try:\n",
    "    os.mkdir(QUERY_DIRECTORY)\n",
    "except Exception as e:\n",
    "    if e.errno == 17:\n",
    "        # the directory already exists\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be67f9a-979b-429c-805e-95b05b023728",
   "metadata": {},
   "source": [
    "### Download All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ae91409-8d6a-4fb9-a26a-70a1487ed0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_urls_from_tlc_page():\n",
    "    response = requests.get(TLC_URL)\n",
    "    html = response.content\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f70e242-38bb-431f-abb3-b0405beb1b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifies all of the yellow and fhvhv parquet files for years 2020 - 2024\n",
    "pattern = re.compile(r\".*(yellow|fhvhv).*(2020|2021|2022|2023|2024)-\\d{2}\\.parquet\")\n",
    "\n",
    "def filter_parquet_urls():\n",
    "    html = get_all_urls_from_tlc_page()\n",
    "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    urls = soup.find_all(\"a\", href=pattern)\n",
    "    parquet_urls = [link[\"href\"].strip() for link in urls]\n",
    "    return parquet_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c8e93ae-18cb-4edf-aaec-bec22b88b000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'parquet_files' already exists.\n"
     ]
    }
   ],
   "source": [
    "folder_name = \"parquet_files\"\n",
    "\n",
    "# Check if the folder exists\n",
    "if not os.path.exists(folder_name):\n",
    "    os.mkdir(folder_name)\n",
    "    print(f\"Folder '{folder_name}' created successfully!\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_name}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b99805f5-a06a-4324-8c97-692e7a7f9ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parses the filename from the link and then downloads the files one by one\n",
    "def download_parquet_files():\n",
    "    for link in filter_parquet_urls():\n",
    "        filename = link.split(\"/\")[-1]\n",
    "        r = requests.get(link)\n",
    "        with open(f\"parquet_files/{filename}\", \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "\n",
    "#run the first time to download data\n",
    "#download_parquet_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d53e24",
   "metadata": {},
   "source": [
    "### Load Taxi Zones & Parquet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "58708809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads the shape file\n",
    "def load_taxi_zones(shapefile):\n",
    "    taxi_zones = gpd.read_file(shapefile)\n",
    "    return taxi_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8171ce1-7305-4091-b7ba-72f6a7799987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OBJECTID  Shape_Leng  Shape_Area                     zone  LocationID  \\\n",
      "0         1    0.116357    0.000782           Newark Airport           1   \n",
      "1         2    0.433470    0.004866              Jamaica Bay           2   \n",
      "2         3    0.084341    0.000314  Allerton/Pelham Gardens           3   \n",
      "3         4    0.043567    0.000112            Alphabet City           4   \n",
      "4         5    0.092146    0.000498            Arden Heights           5   \n",
      "\n",
      "         borough                                           geometry  \n",
      "0            EWR  POLYGON ((933100.918 192536.086, 933091.011 19...  \n",
      "1         Queens  MULTIPOLYGON (((1033269.244 172126.008, 103343...  \n",
      "2          Bronx  POLYGON ((1026308.77 256767.698, 1026495.593 2...  \n",
      "3      Manhattan  POLYGON ((992073.467 203714.076, 992068.667 20...  \n",
      "4  Staten Island  POLYGON ((935843.31 144283.336, 936046.565 144...  \n"
     ]
    }
   ],
   "source": [
    "gdf_taxi_zones = load_taxi_zones(TAXI_ZONES_SHAPEFILE)\n",
    "print(gdf_taxi_zones.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64f2431c-4839-469e-a375-327a698e4356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>zone</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>borough</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.116357</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>POLYGON ((-74.18445 40.695, -74.18449 40.6951,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.433470</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>MULTIPOLYGON (((-73.82338 40.63899, -73.82277 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.084341</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((-73.84793 40.87134, -73.84725 40.870...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((-73.97177 40.72582, -73.97179 40.725...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.092146</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>POLYGON ((-74.17422 40.56257, -74.17349 40.562...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>259</td>\n",
       "      <td>0.126750</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>Woodlawn/Wakefield</td>\n",
       "      <td>259</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((-73.85107 40.91037, -73.85207 40.909...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>260</td>\n",
       "      <td>0.133514</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>Woodside</td>\n",
       "      <td>260</td>\n",
       "      <td>Queens</td>\n",
       "      <td>POLYGON ((-73.90175 40.76078, -73.90147 40.759...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>0.027120</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>World Trade Center</td>\n",
       "      <td>261</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((-74.01333 40.70503, -74.01327 40.704...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>262</td>\n",
       "      <td>0.049064</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>Yorkville East</td>\n",
       "      <td>262</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>MULTIPOLYGON (((-73.94383 40.78286, -73.94376 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>263</td>\n",
       "      <td>0.037017</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>263</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((-73.95219 40.77302, -73.95269 40.772...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     OBJECTID  Shape_Leng  Shape_Area                     zone  LocationID  \\\n",
       "0           1    0.116357    0.000782           Newark Airport           1   \n",
       "1           2    0.433470    0.004866              Jamaica Bay           2   \n",
       "2           3    0.084341    0.000314  Allerton/Pelham Gardens           3   \n",
       "3           4    0.043567    0.000112            Alphabet City           4   \n",
       "4           5    0.092146    0.000498            Arden Heights           5   \n",
       "..        ...         ...         ...                      ...         ...   \n",
       "258       259    0.126750    0.000395       Woodlawn/Wakefield         259   \n",
       "259       260    0.133514    0.000422                 Woodside         260   \n",
       "260       261    0.027120    0.000034       World Trade Center         261   \n",
       "261       262    0.049064    0.000122           Yorkville East         262   \n",
       "262       263    0.037017    0.000066           Yorkville West         263   \n",
       "\n",
       "           borough                                           geometry  \n",
       "0              EWR  POLYGON ((-74.18445 40.695, -74.18449 40.6951,...  \n",
       "1           Queens  MULTIPOLYGON (((-73.82338 40.63899, -73.82277 ...  \n",
       "2            Bronx  POLYGON ((-73.84793 40.87134, -73.84725 40.870...  \n",
       "3        Manhattan  POLYGON ((-73.97177 40.72582, -73.97179 40.725...  \n",
       "4    Staten Island  POLYGON ((-74.17422 40.56257, -74.17349 40.562...  \n",
       "..             ...                                                ...  \n",
       "258          Bronx  POLYGON ((-73.85107 40.91037, -73.85207 40.909...  \n",
       "259         Queens  POLYGON ((-73.90175 40.76078, -73.90147 40.759...  \n",
       "260      Manhattan  POLYGON ((-74.01333 40.70503, -74.01327 40.704...  \n",
       "261      Manhattan  MULTIPOLYGON (((-73.94383 40.78286, -73.94376 ...  \n",
       "262      Manhattan  POLYGON ((-73.95219 40.77302, -73.95269 40.772...  \n",
       "\n",
       "[263 rows x 7 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converts taxi zone geometry coordinates to the appropriate coordinate system  \n",
    "gdf_taxi_zones = gdf_taxi_zones.to_crs(epsg=4326)\n",
    "gdf_taxi_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f6da777-79a3-48f2-8871-0d2d9c3aa0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load parquet file into a pandas DataFrame\n",
    "def load_parquet_file(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45a6df80-fe06-41ab-97bc-800f117a9c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         2  2023-01-01 00:32:10   2023-01-01 00:40:36              1.0   \n",
      "1         2  2023-01-01 00:55:08   2023-01-01 01:01:27              1.0   \n",
      "2         2  2023-01-01 00:25:04   2023-01-01 00:37:49              1.0   \n",
      "3         1  2023-01-01 00:03:48   2023-01-01 00:13:25              0.0   \n",
      "4         2  2023-01-01 00:10:29   2023-01-01 00:21:19              1.0   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0           0.97         1.0                  N           161           141   \n",
      "1           1.10         1.0                  N            43           237   \n",
      "2           2.51         1.0                  N            48           238   \n",
      "3           1.90         1.0                  N           138             7   \n",
      "4           1.43         1.0                  N           107            79   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0             2          9.3   1.00      0.5        0.00           0.0   \n",
      "1             1          7.9   1.00      0.5        4.00           0.0   \n",
      "2             1         14.9   1.00      0.5       15.00           0.0   \n",
      "3             1         12.1   7.25      0.5        0.00           0.0   \n",
      "4             1         11.4   1.00      0.5        3.28           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
      "0                    1.0         14.30                   2.5         0.00  \n",
      "1                    1.0         16.90                   2.5         0.00  \n",
      "2                    1.0         34.90                   2.5         0.00  \n",
      "3                    1.0         20.85                   0.0         1.25  \n",
      "4                    1.0         19.68                   2.5         0.00  \n"
     ]
    }
   ],
   "source": [
    "# load a random yellow taxi trip parquet file to check if the function works correctly for testing purposes\n",
    "example = os.path.join(PARQUET_FILES, \"yellow_tripdata_2023-01.parquet\")\n",
    "example_df = load_parquet_file(example)\n",
    "\n",
    "# preview the data\n",
    "print(example_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09fc14f2-021e-4222-a592-b77e25aa3882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  hvfhs_license_num dispatching_base_num originating_base_num  \\\n",
      "0            HV0003               B03404               B03404   \n",
      "1            HV0003               B03404               B03404   \n",
      "2            HV0003               B03404               B03404   \n",
      "3            HV0003               B03404               B03404   \n",
      "4            HV0003               B03404               B03404   \n",
      "\n",
      "     request_datetime   on_scene_datetime     pickup_datetime  \\\n",
      "0 2023-01-01 00:18:06 2023-01-01 00:19:24 2023-01-01 00:19:38   \n",
      "1 2023-01-01 00:48:42 2023-01-01 00:56:20 2023-01-01 00:58:39   \n",
      "2 2023-01-01 00:15:35 2023-01-01 00:20:14 2023-01-01 00:20:27   \n",
      "3 2023-01-01 00:35:24 2023-01-01 00:39:30 2023-01-01 00:41:05   \n",
      "4 2023-01-01 00:43:15 2023-01-01 00:51:10 2023-01-01 00:52:47   \n",
      "\n",
      "     dropoff_datetime  PULocationID  DOLocationID  trip_miles  ...  sales_tax  \\\n",
      "0 2023-01-01 00:48:07            48            68        0.94  ...       2.30   \n",
      "1 2023-01-01 01:33:08           246           163        2.78  ...       5.34   \n",
      "2 2023-01-01 00:37:54             9           129        8.81  ...       2.16   \n",
      "3 2023-01-01 00:48:16           129           129        0.67  ...       1.22   \n",
      "4 2023-01-01 01:04:51           129            92        4.38  ...       1.82   \n",
      "\n",
      "   congestion_surcharge  airport_fee  tips  driver_pay  shared_request_flag  \\\n",
      "0                  2.75          0.0  5.22       27.83                    N   \n",
      "1                  2.75          0.0  0.00       50.15                    N   \n",
      "2                  0.00          0.0  0.00       20.22                    N   \n",
      "3                  0.00          0.0  0.00        7.90                    N   \n",
      "4                  0.00          0.0  0.00       16.48                    N   \n",
      "\n",
      "   shared_match_flag  access_a_ride_flag  wav_request_flag wav_match_flag  \n",
      "0                  N                                     N              N  \n",
      "1                  N                                     N              N  \n",
      "2                  N                                     N              N  \n",
      "3                  N                                     N              N  \n",
      "4                  N                                     N              N  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# load a random High-Volume For-Hire Vehicle trip parquet file to check if the function works correctly\n",
    "example2 = os.path.join(PARQUET_FILES, \"fhvhv_tripdata_2023-01.parquet\")\n",
    "example_df2 = load_parquet_file(example2)\n",
    "\n",
    "# preview the data\n",
    "print(example_df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c8ea86a-5f05-4c0a-80d8-4c3a22b318bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hvfhs_license_num', 'dispatching_base_num', 'originating_base_num',\n",
       "       'request_datetime', 'on_scene_datetime', 'pickup_datetime',\n",
       "       'dropoff_datetime', 'PULocationID', 'DOLocationID', 'trip_miles',\n",
       "       'trip_time', 'base_passenger_fare', 'tolls', 'bcf', 'sales_tax',\n",
       "       'congestion_surcharge', 'airport_fee', 'tips', 'driver_pay',\n",
       "       'shared_request_flag', 'shared_match_flag', 'access_a_ride_flag',\n",
       "       'wav_request_flag', 'wav_match_flag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "054df826-d223-42e1-a063-e8950b87e59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
       "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
       "       'total_amount', 'congestion_surcharge', 'airport_fee'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e226fb-c4e8-4548-8e42-d30100b34707",
   "metadata": {},
   "source": [
    "### Cleaning and Filtering\n",
    "* Remove all non-Uber data from fhvhv\n",
    "* Remove all invalid pickup and dropoff location IDs for both uber and yellow taxi, where ID is greater than 263 using the `shp` file\n",
    "* Remove unnecessary columns and only keeping columns needed to answer questions in the other parts of this project\n",
    "* Remove invalid data points (use your discretion!)\n",
    "* normalize column names; \n",
    "normalieg and using appropriate column types for the respective dat\n",
    "\n",
    "* Remove trips from both uber and yellow taxi that start and/or end outside of the following latitude/longitude coordinate box: (40.560445, -74.242330) and (40.908524, -73.71704).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5acd1bf2-2e19-49a5-a944-9216dcaf0bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_15944\\103723099.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  gdf_taxi_zones['centroid'] = gdf_taxi_zones.geometry.centroid\n"
     ]
    }
   ],
   "source": [
    "#Compute the center of the taxi zones for easier comparison and adds a column to the df of our shapefile \n",
    "gdf_taxi_zones['centroid'] = gdf_taxi_zones.geometry.centroid\n",
    "\n",
    "#Rename 'LocationID' to 'location_id' for consistency\n",
    "gdf_taxi_zones = gdf_taxi_zones.rename(columns={'LocationID': 'location_id'})\n",
    "\n",
    "#Removes the bulky geometry column after using it to compute centroid. \n",
    "gdf_taxi_zones = gdf_taxi_zones[['zone', 'location_id', 'centroid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f9f09b68-041e-4cac-a0b5-591d043274e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone</th>\n",
       "      <th>location_id</th>\n",
       "      <th>centroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (-74.174 40.69183)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>2</td>\n",
       "      <td>POINT (-73.8313 40.61675)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>3</td>\n",
       "      <td>POINT (-73.84742 40.86447)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>4</td>\n",
       "      <td>POINT (-73.97697 40.72375)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>5</td>\n",
       "      <td>POINT (-74.18848 40.55266)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Woodlawn/Wakefield</td>\n",
       "      <td>259</td>\n",
       "      <td>POINT (-73.85222 40.89793)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Woodside</td>\n",
       "      <td>260</td>\n",
       "      <td>POINT (-73.90631 40.74423)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>World Trade Center</td>\n",
       "      <td>261</td>\n",
       "      <td>POINT (-74.01302 40.70914)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Yorkville East</td>\n",
       "      <td>262</td>\n",
       "      <td>POINT (-73.94651 40.77593)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>263</td>\n",
       "      <td>POINT (-73.95101 40.77877)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        zone  location_id                    centroid\n",
       "0             Newark Airport            1    POINT (-74.174 40.69183)\n",
       "1                Jamaica Bay            2   POINT (-73.8313 40.61675)\n",
       "2    Allerton/Pelham Gardens            3  POINT (-73.84742 40.86447)\n",
       "3              Alphabet City            4  POINT (-73.97697 40.72375)\n",
       "4              Arden Heights            5  POINT (-74.18848 40.55266)\n",
       "..                       ...          ...                         ...\n",
       "258       Woodlawn/Wakefield          259  POINT (-73.85222 40.89793)\n",
       "259                 Woodside          260  POINT (-73.90631 40.74423)\n",
       "260       World Trade Center          261  POINT (-74.01302 40.70914)\n",
       "261           Yorkville East          262  POINT (-73.94651 40.77593)\n",
       "262           Yorkville West          263  POINT (-73.95101 40.77877)\n",
       "\n",
       "[263 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_taxi_zones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculate Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae9ffcb8-7268-45ba-af74-752e9710a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default: 95% confidence interval, 5% margin of error, p of 0.5 (estimated) proportion of the population which has the attribute in question\n",
    "def cochran_sample_size(population_size):\n",
    "    z_score=1.96\n",
    "    margin_of_error=0.05\n",
    "    p=0.5\n",
    "    sample_size = ((z_score**2)*p*(1-p)) / (margin_of_error**2)\n",
    "    adjusted_sample_size = sample_size / (1 + ((sample_size-1)/population_size))\n",
    "\n",
    "    return int(adjusted_sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33eed4-b2e9-4ab3-94a8-59f04e464c98",
   "metadata": {},
   "source": [
    "### Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f506ca76-802b-414c-a2b0-3389bc66dfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter function to remove unecessary rows\n",
    "def filter_data(data):\n",
    "    #Ensure PU and DO locations are within valid location IDs (<= 263)\n",
    "    data = data[(data['pickup_location_id'] <= 263) & (data['dropoff_location_id'] <= 263)]\n",
    "    #Filters out rides where pickup and dropoff locations are the same\n",
    "    filtered_data = data[data['trip_distance'] != 0]\n",
    "        \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8504d167-f1f2-45ee-878f-14a802f71de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes trips from both uber and yellow taxi that start and/or end outside of the following latitude/longitude coordinate box:\n",
    "def find_centroid(data):\n",
    "    LAT_MIN, LON_MIN = 40.560445, -74.242330\n",
    "    LAT_MAX, LON_MAX = 40.908524, -73.717047\n",
    "    \n",
    "    # Extract latitude and longitude from the 'centroid' column using .apply()\n",
    "    data['centroid_lat'] = data['centroid'].apply(lambda point: point.y)\n",
    "    data['centroid_lon'] = data['centroid'].apply(lambda point: point.x)\n",
    "    \n",
    "    # Filter rows where the centroid coordinates are within the bounding coordinate box\n",
    "    centroid_data = data[\n",
    "        (data['centroid_lat'] >= LAT_MIN) & (data['centroid_lat'] <= LAT_MAX) &\n",
    "        (data['centroid_lon'] >= LON_MIN) & (data['centroid_lon'] <= LON_MAX)\n",
    "    ]\n",
    "    return centroid_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Process Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a35b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab all of the parquet files in the directory. glob.glob is used to identify/match the pattern, path.join retrieves all the paths \n",
    "all_taxi_parquet_files = glob.glob(os.path.join(PARQUET_FILES, \"*yellow*.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c7f09ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_15944\\4192337244.py:39: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  sampled_taxi_data = pd.concat(sampled_taxi_dfs)\n"
     ]
    }
   ],
   "source": [
    "taxi_columns_mapping = {\n",
    "    'tpep_pickup_datetime': 'pickup_datetime',\n",
    "    'tpep_dropoff_datetime': 'dropoff_datetime',\n",
    "    'extra': 'rush_hour_surcharge',\n",
    "    'PULocationID': 'pickup_location_id',\n",
    "    'DOLocationID': 'dropoff_location_id',\n",
    "     'fare_amount': 'base_passenger_fare',\n",
    "    'RatecodeID': 'rate_code_id'\n",
    "}\n",
    "\n",
    "#Make a list of just the columns we need for analysis\n",
    "columns_to_keep = [\n",
    "    'pickup_datetime', 'dropoff_datetime', 'trip_distance', 'rate_code_id',\n",
    "    'pickup_location_id', 'dropoff_location_id', 'base_passenger_fare', 'rush_hour_surcharge', 'mta_tax',\n",
    "    'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount',\n",
    "    'congestion_surcharge', 'airport_fee'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "#Create samples of all taxi parquet files according to cochran's sample size formula. Later, we concatenate all sample dfs into one df. \n",
    "sampled_taxi_dfs = []\n",
    "\n",
    "for file_path in all_taxi_parquet_files:      \n",
    "    taxi_df = load_parquet_file(file_path) #Makes a df for every parquet file \n",
    "    taxi_df = taxi_df.rename(columns=taxi_columns_mapping)\n",
    "    \n",
    "    population_size = len(taxi_df)\n",
    "    sample_size = cochran_sample_size(population_size)\n",
    "    sampled_taxi_df = taxi_df.sample(n=sample_size, random_state=42)\n",
    "    #We found that there were a few files that did not have airport_fee as a column. We populate airport_fee with NaN for such parquet files.\n",
    "    for col in columns_to_keep:  \n",
    "        if col not in sampled_taxi_df.columns:\n",
    "            sampled_taxi_df[col] = np.nan \n",
    "    sampled_taxi_df = sampled_taxi_df[columns_to_keep]\n",
    "    sampled_taxi_dfs.append(sampled_taxi_df)\n",
    "\n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "sampled_taxi_data = pd.concat(sampled_taxi_dfs)\n",
    "\n",
    "sampled_taxi_data = filter_data(sampled_taxi_data)\n",
    "\n",
    "# Make a single df that includes the taxi rides and their corresponding coordinates by merging the shape file with the ride files.\n",
    "final_taxi_data = pd.merge(sampled_taxi_data, gdf_taxi_zones, left_on = 'pickup_location_id', right_on = 'location_id', how=\"inner\")\n",
    "\n",
    "final_taxi_data = find_centroid(final_taxi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "10ebd75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>rate_code_id</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>dropoff_location_id</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>rush_hour_surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>zone</th>\n",
       "      <th>location_id</th>\n",
       "      <th>centroid</th>\n",
       "      <th>centroid_lat</th>\n",
       "      <th>centroid_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-25 10:49:58</td>\n",
       "      <td>2020-01-25 11:07:35</td>\n",
       "      <td>3.28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142</td>\n",
       "      <td>246</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lincoln Square East</td>\n",
       "      <td>142</td>\n",
       "      <td>POINT (-73.98153 40.77363)</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>-73.981532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-15 07:30:08</td>\n",
       "      <td>2020-01-15 07:40:01</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>238</td>\n",
       "      <td>166</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Upper West Side North</td>\n",
       "      <td>238</td>\n",
       "      <td>POINT (-73.97305 40.7917)</td>\n",
       "      <td>40.791705</td>\n",
       "      <td>-73.973049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-09 06:29:09</td>\n",
       "      <td>2020-01-09 06:35:44</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>164</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Garment District</td>\n",
       "      <td>100</td>\n",
       "      <td>POINT (-73.98879 40.75351)</td>\n",
       "      <td>40.753513</td>\n",
       "      <td>-73.988787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-26 12:24:04</td>\n",
       "      <td>2020-01-26 12:29:15</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161</td>\n",
       "      <td>43</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Midtown Center</td>\n",
       "      <td>161</td>\n",
       "      <td>POINT (-73.9777 40.75803)</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.977698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-30 07:57:53</td>\n",
       "      <td>2020-01-30 08:10:19</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>229</td>\n",
       "      <td>262</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sutton Place/Turtle Bay North</td>\n",
       "      <td>229</td>\n",
       "      <td>POINT (-73.96515 40.75673)</td>\n",
       "      <td>40.756729</td>\n",
       "      <td>-73.965146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pickup_datetime    dropoff_datetime  trip_distance  rate_code_id  \\\n",
       "0 2020-01-25 10:49:58 2020-01-25 11:07:35           3.28           1.0   \n",
       "1 2020-01-15 07:30:08 2020-01-15 07:40:01           1.75           1.0   \n",
       "2 2020-01-09 06:29:09 2020-01-09 06:35:44           0.87           1.0   \n",
       "3 2020-01-26 12:24:04 2020-01-26 12:29:15           0.98           1.0   \n",
       "4 2020-01-30 07:57:53 2020-01-30 08:10:19           1.30           1.0   \n",
       "\n",
       "   pickup_location_id  dropoff_location_id  base_passenger_fare  \\\n",
       "0                 142                  246                 14.0   \n",
       "1                 238                  166                  8.5   \n",
       "2                 100                  164                  5.5   \n",
       "3                 161                   43                  5.5   \n",
       "4                 229                  262                  9.0   \n",
       "\n",
       "   rush_hour_surcharge  mta_tax  tip_amount  tolls_amount  \\\n",
       "0                  0.0      0.5        1.70           0.0   \n",
       "1                  0.0      0.5        1.20           0.0   \n",
       "2                  0.0      0.5        0.00           0.0   \n",
       "3                  0.0      0.5        0.00           0.0   \n",
       "4                  2.5      0.5        2.45           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \\\n",
       "0                    0.3         19.00                   2.5          NaN   \n",
       "1                    0.3         13.00                   2.5          NaN   \n",
       "2                    0.3          8.80                   2.5          NaN   \n",
       "3                    0.3          8.80                   2.5          NaN   \n",
       "4                    0.3         14.75                   2.5          NaN   \n",
       "\n",
       "                            zone  location_id                    centroid  \\\n",
       "0            Lincoln Square East          142  POINT (-73.98153 40.77363)   \n",
       "1          Upper West Side North          238   POINT (-73.97305 40.7917)   \n",
       "2               Garment District          100  POINT (-73.98879 40.75351)   \n",
       "3                 Midtown Center          161   POINT (-73.9777 40.75803)   \n",
       "4  Sutton Place/Turtle Bay North          229  POINT (-73.96515 40.75673)   \n",
       "\n",
       "   centroid_lat  centroid_lon  \n",
       "0     40.773633    -73.981532  \n",
       "1     40.791705    -73.973049  \n",
       "2     40.753513    -73.988787  \n",
       "3     40.758028    -73.977698  \n",
       "4     40.756729    -73.965146  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_taxi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c9da7089-3f6b-4f93-a22e-76bf554daca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20826 entries, 0 to 20828\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   pickup_datetime        20826 non-null  datetime64[us]\n",
      " 1   dropoff_datetime       20826 non-null  datetime64[us]\n",
      " 2   trip_distance          20826 non-null  float64       \n",
      " 3   rate_code_id           19770 non-null  float64       \n",
      " 4   pickup_location_id     20826 non-null  int64         \n",
      " 5   dropoff_location_id    20826 non-null  int64         \n",
      " 6   base_passenger_fare    20826 non-null  float64       \n",
      " 7   rush_hour_surcharge    20826 non-null  float64       \n",
      " 8   mta_tax                20826 non-null  float64       \n",
      " 9   tip_amount             20826 non-null  float64       \n",
      " 10  tolls_amount           20826 non-null  float64       \n",
      " 11  improvement_surcharge  20826 non-null  float64       \n",
      " 12  total_amount           20826 non-null  float64       \n",
      " 13  congestion_surcharge   19770 non-null  float64       \n",
      " 14  airport_fee            7947 non-null   float64       \n",
      " 15  zone                   20826 non-null  object        \n",
      " 16  location_id            20826 non-null  int32         \n",
      " 17  centroid               20826 non-null  geometry      \n",
      " 18  centroid_lat           20826 non-null  float64       \n",
      " 19  centroid_lon           20826 non-null  float64       \n",
      "dtypes: datetime64[us](2), float64(13), geometry(1), int32(1), int64(2), object(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "final_taxi_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "50c85e25-6416-4c16-b98c-09596cdc6865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>rate_code_id</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>dropoff_location_id</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>rush_hour_surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>location_id</th>\n",
       "      <th>centroid_lat</th>\n",
       "      <th>centroid_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20826</td>\n",
       "      <td>20826</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>19770.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>19770.000000</td>\n",
       "      <td>7947.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "      <td>20826.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-05-01 10:17:07.596274</td>\n",
       "      <td>2022-05-01 10:33:09.629309</td>\n",
       "      <td>3.275384</td>\n",
       "      <td>1.415023</td>\n",
       "      <td>164.151157</td>\n",
       "      <td>160.661001</td>\n",
       "      <td>15.153432</td>\n",
       "      <td>1.205869</td>\n",
       "      <td>0.490733</td>\n",
       "      <td>2.680401</td>\n",
       "      <td>0.431877</td>\n",
       "      <td>0.543945</td>\n",
       "      <td>22.188515</td>\n",
       "      <td>2.297547</td>\n",
       "      <td>0.086825</td>\n",
       "      <td>164.151157</td>\n",
       "      <td>40.753285</td>\n",
       "      <td>-73.966859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 00:11:06</td>\n",
       "      <td>2020-01-01 00:30:50</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-81.520000</td>\n",
       "      <td>-7.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34.200000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-108.200000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.576961</td>\n",
       "      <td>-74.029892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-02-28 21:30:14.250000</td>\n",
       "      <td>2021-02-28 21:36:58.750000</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-73.989845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-04-30 15:36:52.500000</td>\n",
       "      <td>2022-04-30 16:06:25</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.977698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-06-29 14:40:03</td>\n",
       "      <td>2023-06-29 14:50:15.250000</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.360000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>-73.961764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-08-31 22:43:47</td>\n",
       "      <td>2024-08-31 23:26:23</td>\n",
       "      <td>67.900000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>209.500000</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>262.700000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>40.899529</td>\n",
       "      <td>-73.739337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.121171</td>\n",
       "      <td>6.028092</td>\n",
       "      <td>65.215425</td>\n",
       "      <td>70.490221</td>\n",
       "      <td>13.948344</td>\n",
       "      <td>1.512793</td>\n",
       "      <td>0.089069</td>\n",
       "      <td>3.157641</td>\n",
       "      <td>1.825400</td>\n",
       "      <td>0.351174</td>\n",
       "      <td>17.759500</td>\n",
       "      <td>0.735558</td>\n",
       "      <td>0.321505</td>\n",
       "      <td>65.215425</td>\n",
       "      <td>0.032466</td>\n",
       "      <td>0.045223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pickup_datetime            dropoff_datetime  trip_distance  \\\n",
       "count                       20826                       20826   20826.000000   \n",
       "mean   2022-05-01 10:17:07.596274  2022-05-01 10:33:09.629309       3.275384   \n",
       "min           2020-01-01 00:11:06         2020-01-01 00:30:50       0.010000   \n",
       "25%    2021-02-28 21:30:14.250000  2021-02-28 21:36:58.750000       1.090000   \n",
       "50%    2022-04-30 15:36:52.500000         2022-04-30 16:06:25       1.800000   \n",
       "75%           2023-06-29 14:40:03  2023-06-29 14:50:15.250000       3.310000   \n",
       "max           2024-08-31 22:43:47         2024-08-31 23:26:23      67.900000   \n",
       "std                           NaN                         NaN       4.121171   \n",
       "\n",
       "       rate_code_id  pickup_location_id  dropoff_location_id  \\\n",
       "count  19770.000000        20826.000000         20826.000000   \n",
       "mean       1.415023          164.151157           160.661001   \n",
       "min        1.000000            4.000000             1.000000   \n",
       "25%        1.000000          132.000000           107.000000   \n",
       "50%        1.000000          162.000000           161.000000   \n",
       "75%        1.000000          234.000000           234.000000   \n",
       "max       99.000000          263.000000           263.000000   \n",
       "std        6.028092           65.215425            70.490221   \n",
       "\n",
       "       base_passenger_fare  rush_hour_surcharge       mta_tax    tip_amount  \\\n",
       "count         20826.000000         20826.000000  20826.000000  20826.000000   \n",
       "mean             15.153432             1.205869      0.490733      2.680401   \n",
       "min             -81.520000            -7.500000     -0.500000      0.000000   \n",
       "25%               7.200000             0.000000      0.500000      0.000000   \n",
       "50%              10.700000             0.500000      0.500000      2.160000   \n",
       "75%              17.000000             2.500000      0.500000      3.440000   \n",
       "max             209.500000            11.750000      0.500000     50.000000   \n",
       "std              13.948344             1.512793      0.089069      3.157641   \n",
       "\n",
       "       tolls_amount  improvement_surcharge  total_amount  \\\n",
       "count  20826.000000           20826.000000  20826.000000   \n",
       "mean       0.431877               0.543945     22.188515   \n",
       "min      -34.200000              -1.000000   -108.200000   \n",
       "25%        0.000000               0.300000     12.600000   \n",
       "50%        0.000000               0.300000     16.800000   \n",
       "75%        0.000000               1.000000     24.360000   \n",
       "max       40.000000               1.000000    262.700000   \n",
       "std        1.825400               0.351174     17.759500   \n",
       "\n",
       "       congestion_surcharge  airport_fee   location_id  centroid_lat  \\\n",
       "count          19770.000000  7947.000000  20826.000000  20826.000000   \n",
       "mean               2.297547     0.086825    164.151157     40.753285   \n",
       "min               -2.500000    -1.250000      4.000000     40.576961   \n",
       "25%                2.500000     0.000000    132.000000     40.740337   \n",
       "50%                2.500000     0.000000    162.000000     40.758028   \n",
       "75%                2.500000     0.000000    234.000000     40.773633   \n",
       "max                2.500000     1.250000    263.000000     40.899529   \n",
       "std                0.735558     0.321505     65.215425      0.032466   \n",
       "\n",
       "       centroid_lon  \n",
       "count  20826.000000  \n",
       "mean     -73.966859  \n",
       "min      -74.029892  \n",
       "25%      -73.989845  \n",
       "50%      -73.977698  \n",
       "75%      -73.961764  \n",
       "max      -73.739337  \n",
       "std        0.045223  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_taxi_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d0658d4-173f-4290-abd8-022b5b9e5560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab all of the parquet files in the directory. glob.glob is used to identify/match the pattern, path.join retrieves all the paths \n",
    "all_fhvhv_parquet_files = glob.glob(os.path.join(PARQUET_FILES, \"*fhvhv*.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4c4a1fb4-01b4-43ff-b5e7-492ce2fc3bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_15944\\3122417029.py:30: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  sampled_uber_data = pd.concat(sampled_uber_dfs)\n"
     ]
    }
   ],
   "source": [
    "uber_columns_mapping = {\n",
    "    'trip_miles': 'trip_distance',\n",
    "    'PULocationID': 'pickup_location_id',\n",
    "    'DOLocationID': 'dropoff_location_id',\n",
    "    'tolls': 'tolls_amount',\n",
    "    'tips': 'tip_amount',\n",
    "    'bcf': 'black_car_fund_fee',\n",
    "    \n",
    "}\n",
    "\n",
    "#Create samples of all uber parquet files according to cochran's sample size formula. Later, we concatenate all sample dfs into one df. \n",
    "sampled_uber_dfs = []\n",
    "columns_to_keep = ['hvfhs_license_num',\n",
    "       'request_datetime', 'pickup_datetime',\n",
    "       'dropoff_datetime', 'pickup_location_id', 'dropoff_location_id', 'trip_distance',\n",
    "        'base_passenger_fare', 'tolls_amount', 'black_car_fund_fee', 'sales_tax',\n",
    "       'congestion_surcharge', 'airport_fee', 'tip_amount']\n",
    "\n",
    "for file_path in all_fhvhv_parquet_files:      \n",
    "    uber_df = load_parquet_file(file_path) #Makes a df for every parquet file \n",
    "    uber_df = uber_df.rename(columns=uber_columns_mapping)\n",
    "    uber_df = uber_df[uber_df['hvfhs_license_num'] == 'HV0003'] #Filters out non-uber rides from the hvfhs files before creating samples\n",
    "    population_size = len(uber_df)\n",
    "    sample_size = cochran_sample_size(population_size)\n",
    "    sampled_uber_df = uber_df.sample(n=sample_size, random_state=42)\n",
    "    sampled_uber_df = sampled_uber_df[columns_to_keep]\n",
    "    sampled_uber_dfs.append(sampled_uber_df)\n",
    "\n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "sampled_uber_data = pd.concat(sampled_uber_dfs)\n",
    "\n",
    "sampled_uber_data = filter_data(sampled_uber_data)\n",
    "\n",
    "# Make a single df that includes the taxi rides and their corresponding coordinates by merging the shape file with the ride files.\n",
    "final_uber_data = pd.merge(sampled_uber_data, gdf_taxi_zones, left_on = 'pickup_location_id', right_on = 'location_id', how=\"inner\")\n",
    "\n",
    "final_uber_data = find_centroid(final_uber_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "339997e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>dropoff_location_id</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>black_car_fund_fee</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>zone</th>\n",
       "      <th>location_id</th>\n",
       "      <th>centroid</th>\n",
       "      <th>centroid_lat</th>\n",
       "      <th>centroid_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2020-01-26 22:19:19</td>\n",
       "      <td>2020-01-26 22:21:28</td>\n",
       "      <td>2020-01-26 22:44:27</td>\n",
       "      <td>48</td>\n",
       "      <td>80</td>\n",
       "      <td>6.95</td>\n",
       "      <td>27.22</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.83</td>\n",
       "      <td>2.96</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Clinton East</td>\n",
       "      <td>48</td>\n",
       "      <td>POINT (-73.98984 40.76225)</td>\n",
       "      <td>40.762253</td>\n",
       "      <td>-73.989845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2020-01-19 15:28:56</td>\n",
       "      <td>2020-01-19 15:34:47</td>\n",
       "      <td>2020-01-19 16:00:12</td>\n",
       "      <td>114</td>\n",
       "      <td>138</td>\n",
       "      <td>10.78</td>\n",
       "      <td>32.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2.89</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Greenwich Village South</td>\n",
       "      <td>114</td>\n",
       "      <td>POINT (-73.99738 40.72834)</td>\n",
       "      <td>40.728340</td>\n",
       "      <td>-73.997380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2020-01-25 20:55:33</td>\n",
       "      <td>2020-01-25 20:58:45</td>\n",
       "      <td>2020-01-25 21:04:11</td>\n",
       "      <td>61</td>\n",
       "      <td>225</td>\n",
       "      <td>1.00</td>\n",
       "      <td>7.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Crown Heights North</td>\n",
       "      <td>61</td>\n",
       "      <td>POINT (-73.93929 40.67447)</td>\n",
       "      <td>40.674469</td>\n",
       "      <td>-73.939287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2020-01-11 08:39:09</td>\n",
       "      <td>2020-01-11 08:42:05</td>\n",
       "      <td>2020-01-11 08:49:12</td>\n",
       "      <td>91</td>\n",
       "      <td>39</td>\n",
       "      <td>1.95</td>\n",
       "      <td>5.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Flatlands</td>\n",
       "      <td>91</td>\n",
       "      <td>POINT (-73.9301 40.62627)</td>\n",
       "      <td>40.626273</td>\n",
       "      <td>-73.930097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>2020-01-19 18:13:08</td>\n",
       "      <td>2020-01-19 18:17:31</td>\n",
       "      <td>2020-01-19 18:34:47</td>\n",
       "      <td>256</td>\n",
       "      <td>52</td>\n",
       "      <td>4.23</td>\n",
       "      <td>17.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Williamsburg (South Side)</td>\n",
       "      <td>256</td>\n",
       "      <td>POINT (-73.9599 40.71088)</td>\n",
       "      <td>40.710880</td>\n",
       "      <td>-73.959905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num    request_datetime     pickup_datetime  \\\n",
       "0            HV0003 2020-01-26 22:19:19 2020-01-26 22:21:28   \n",
       "1            HV0003 2020-01-19 15:28:56 2020-01-19 15:34:47   \n",
       "2            HV0003 2020-01-25 20:55:33 2020-01-25 20:58:45   \n",
       "3            HV0003 2020-01-11 08:39:09 2020-01-11 08:42:05   \n",
       "4            HV0003 2020-01-19 18:13:08 2020-01-19 18:17:31   \n",
       "\n",
       "     dropoff_datetime  pickup_location_id  dropoff_location_id  trip_distance  \\\n",
       "0 2020-01-26 22:44:27                  48                   80           6.95   \n",
       "1 2020-01-19 16:00:12                 114                  138          10.78   \n",
       "2 2020-01-25 21:04:11                  61                  225           1.00   \n",
       "3 2020-01-11 08:49:12                  91                   39           1.95   \n",
       "4 2020-01-19 18:34:47                 256                   52           4.23   \n",
       "\n",
       "   base_passenger_fare  tolls_amount  black_car_fund_fee  sales_tax  \\\n",
       "0                27.22          6.12                0.83       2.96   \n",
       "1                32.52          0.00                0.81       2.89   \n",
       "2                 7.19          0.00                0.18       0.64   \n",
       "3                 5.78          0.00                0.14       0.51   \n",
       "4                17.65          0.00                0.36       1.18   \n",
       "\n",
       "   congestion_surcharge  airport_fee  tip_amount                       zone  \\\n",
       "0                  2.75          NaN         0.0               Clinton East   \n",
       "1                  2.75          NaN         0.0    Greenwich Village South   \n",
       "2                  0.00          NaN         0.0        Crown Heights North   \n",
       "3                  0.00          NaN         0.0                  Flatlands   \n",
       "4                  0.00          NaN         1.0  Williamsburg (South Side)   \n",
       "\n",
       "   location_id                    centroid  centroid_lat  centroid_lon  \n",
       "0           48  POINT (-73.98984 40.76225)     40.762253    -73.989845  \n",
       "1          114  POINT (-73.99738 40.72834)     40.728340    -73.997380  \n",
       "2           61  POINT (-73.93929 40.67447)     40.674469    -73.939287  \n",
       "3           91   POINT (-73.9301 40.62627)     40.626273    -73.930097  \n",
       "4          256   POINT (-73.9599 40.71088)     40.710880    -73.959905  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_uber_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "74d783db-e527-4847-bf70-2d7428ea3897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20678 entries, 0 to 20731\n",
      "Data columns (total 19 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   hvfhs_license_num     20678 non-null  object        \n",
      " 1   request_datetime      20678 non-null  datetime64[us]\n",
      " 2   pickup_datetime       20678 non-null  datetime64[us]\n",
      " 3   dropoff_datetime      20678 non-null  datetime64[us]\n",
      " 4   pickup_location_id    20678 non-null  int64         \n",
      " 5   dropoff_location_id   20678 non-null  int64         \n",
      " 6   trip_distance         20678 non-null  float64       \n",
      " 7   base_passenger_fare   20678 non-null  float64       \n",
      " 8   tolls_amount          20678 non-null  float64       \n",
      " 9   black_car_fund_fee    20678 non-null  float64       \n",
      " 10  sales_tax             20678 non-null  float64       \n",
      " 11  congestion_surcharge  20678 non-null  float64       \n",
      " 12  airport_fee           15107 non-null  float64       \n",
      " 13  tip_amount            20678 non-null  float64       \n",
      " 14  zone                  20678 non-null  object        \n",
      " 15  location_id           20678 non-null  int32         \n",
      " 16  centroid              20678 non-null  geometry      \n",
      " 17  centroid_lat          20678 non-null  float64       \n",
      " 18  centroid_lon          20678 non-null  float64       \n",
      "dtypes: datetime64[us](3), float64(10), geometry(1), int32(1), int64(2), object(2)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "final_uber_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6fddeb14-cd70-4e83-8f93-974642c3bea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>dropoff_location_id</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>black_car_fund_fee</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>location_id</th>\n",
       "      <th>centroid_lat</th>\n",
       "      <th>centroid_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20678</td>\n",
       "      <td>20678</td>\n",
       "      <td>20678</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>15107.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "      <td>20678.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-04-29 03:51:06.178257</td>\n",
       "      <td>2022-04-29 03:55:45.584002</td>\n",
       "      <td>2022-04-29 04:13:38.630138</td>\n",
       "      <td>137.800077</td>\n",
       "      <td>137.759745</td>\n",
       "      <td>4.439277</td>\n",
       "      <td>21.201442</td>\n",
       "      <td>0.656449</td>\n",
       "      <td>0.620884</td>\n",
       "      <td>1.895659</td>\n",
       "      <td>1.052326</td>\n",
       "      <td>0.191468</td>\n",
       "      <td>0.820059</td>\n",
       "      <td>137.800077</td>\n",
       "      <td>40.737434</td>\n",
       "      <td>-73.934434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 01:14:43</td>\n",
       "      <td>2020-01-01 01:21:23</td>\n",
       "      <td>2020-01-01 01:46:38</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-9.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.561994</td>\n",
       "      <td>-74.170887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-02-24 10:25:41.250000</td>\n",
       "      <td>2021-02-24 10:29:33.250000</td>\n",
       "      <td>2021-02-24 10:49:42.250000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>10.490000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>40.690787</td>\n",
       "      <td>-73.984196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-04-25 21:30:18</td>\n",
       "      <td>2022-04-25 21:33:31.500000</td>\n",
       "      <td>2022-04-25 21:42:09</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>16.720000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>40.737699</td>\n",
       "      <td>-73.948789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-06-30 11:11:37</td>\n",
       "      <td>2023-06-30 11:14:15</td>\n",
       "      <td>2023-06-30 11:23:13.250000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>26.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>2.380000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>40.774376</td>\n",
       "      <td>-73.898956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-08-31 23:43:36</td>\n",
       "      <td>2024-08-31 23:49:13</td>\n",
       "      <td>2024-09-01 00:10:26</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>42.660000</td>\n",
       "      <td>255.840000</td>\n",
       "      <td>43.910000</td>\n",
       "      <td>7.950000</td>\n",
       "      <td>23.510000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>40.899529</td>\n",
       "      <td>-73.726655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.489021</td>\n",
       "      <td>75.367212</td>\n",
       "      <td>4.359484</td>\n",
       "      <td>15.753046</td>\n",
       "      <td>2.520313</td>\n",
       "      <td>0.500625</td>\n",
       "      <td>1.450202</td>\n",
       "      <td>1.332477</td>\n",
       "      <td>0.670128</td>\n",
       "      <td>2.429705</td>\n",
       "      <td>75.489021</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>0.065377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 request_datetime             pickup_datetime  \\\n",
       "count                       20678                       20678   \n",
       "mean   2022-04-29 03:51:06.178257  2022-04-29 03:55:45.584002   \n",
       "min           2020-01-01 01:14:43         2020-01-01 01:21:23   \n",
       "25%    2021-02-24 10:25:41.250000  2021-02-24 10:29:33.250000   \n",
       "50%           2022-04-25 21:30:18  2022-04-25 21:33:31.500000   \n",
       "75%           2023-06-30 11:11:37         2023-06-30 11:14:15   \n",
       "max           2024-08-31 23:43:36         2024-08-31 23:49:13   \n",
       "std                           NaN                         NaN   \n",
       "\n",
       "                 dropoff_datetime  pickup_location_id  dropoff_location_id  \\\n",
       "count                       20678        20678.000000         20678.000000   \n",
       "mean   2022-04-29 04:13:38.630138          137.800077           137.759745   \n",
       "min           2020-01-01 01:46:38            3.000000             1.000000   \n",
       "25%    2021-02-24 10:49:42.250000           73.000000            74.000000   \n",
       "50%           2022-04-25 21:42:09          139.000000           138.000000   \n",
       "75%    2023-06-30 11:23:13.250000          211.000000           209.000000   \n",
       "max           2024-09-01 00:10:26          263.000000           263.000000   \n",
       "std                           NaN           75.489021            75.367212   \n",
       "\n",
       "       trip_distance  base_passenger_fare  tolls_amount  black_car_fund_fee  \\\n",
       "count   20678.000000         20678.000000  20678.000000        20678.000000   \n",
       "mean        4.439277            21.201442      0.656449            0.620884   \n",
       "min         0.020000            -9.400000      0.000000            0.000000   \n",
       "25%         1.540000            10.490000      0.000000            0.290000   \n",
       "50%         2.810000            16.720000      0.000000            0.470000   \n",
       "75%         5.710000            26.570000      0.000000            0.770000   \n",
       "max        42.660000           255.840000     43.910000            7.950000   \n",
       "std         4.359484            15.753046      2.520313            0.500625   \n",
       "\n",
       "          sales_tax  congestion_surcharge   airport_fee    tip_amount  \\\n",
       "count  20678.000000          20678.000000  15107.000000  20678.000000   \n",
       "mean       1.895659              1.052326      0.191468      0.820059   \n",
       "min        0.000000              0.000000      0.000000      0.000000   \n",
       "25%        0.910000              0.000000      0.000000      0.000000   \n",
       "50%        1.470000              0.000000      0.000000      0.000000   \n",
       "75%        2.380000              2.750000      0.000000      0.000000   \n",
       "max       23.510000              2.750000      5.000000     40.000000   \n",
       "std        1.450202              1.332477      0.670128      2.429705   \n",
       "\n",
       "        location_id  centroid_lat  centroid_lon  \n",
       "count  20678.000000  20678.000000  20678.000000  \n",
       "mean     137.800077     40.737434    -73.934434  \n",
       "min        3.000000     40.561994    -74.170887  \n",
       "25%       73.000000     40.690787    -73.984196  \n",
       "50%      139.000000     40.737699    -73.948789  \n",
       "75%      211.000000     40.774376    -73.898956  \n",
       "max      263.000000     40.899529    -73.726655  \n",
       "std       75.489021      0.069218      0.065377  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_uber_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ec5370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_weather_csvs(directory):\n",
    "    weather_dfs = []\n",
    "\n",
    "    # Iterate over all files in the given directory\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path, low_memory=False)\n",
    "        # Append the DataFrame to the list\n",
    "        weather_dfs.append(df)\n",
    "    weather_dfs = pd.concat(weather_dfs, ignore_index=True)\n",
    "    return weather_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ff3a175-10a4-4187-88d7-240325c3a672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>MonthlyTotalLiquidPrecipitation</th>\n",
       "      <th>DailyPrecipitation</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>DailyAverageWindSpeed</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "      <th>DailySnowfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-01-01 23:59:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-01-02 04:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-01-02 05:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2020-01-02 06:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2020-01-02 07:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56093</th>\n",
       "      <td>2024-10-22 14:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56094</th>\n",
       "      <td>2024-10-22 15:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56095</th>\n",
       "      <td>2024-10-22 16:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56096</th>\n",
       "      <td>2024-10-22 17:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56097</th>\n",
       "      <td>2024-10-22 18:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8523 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     DATE  LATITUDE  LONGITUDE  \\\n",
       "24    2020-01-01 23:59:00  40.77898  -73.96925   \n",
       "29    2020-01-02 04:51:00  40.77898  -73.96925   \n",
       "30    2020-01-02 05:51:00  40.77898  -73.96925   \n",
       "31    2020-01-02 06:51:00  40.77898  -73.96925   \n",
       "32    2020-01-02 07:51:00  40.77898  -73.96925   \n",
       "...                   ...       ...        ...   \n",
       "56093 2024-10-22 14:51:00  40.77898  -73.96925   \n",
       "56094 2024-10-22 15:51:00  40.77898  -73.96925   \n",
       "56095 2024-10-22 16:51:00  40.77898  -73.96925   \n",
       "56096 2024-10-22 17:51:00  40.77898  -73.96925   \n",
       "56097 2024-10-22 18:51:00  40.77898  -73.96925   \n",
       "\n",
       "      MonthlyTotalLiquidPrecipitation DailyPrecipitation HourlyPrecipitation  \\\n",
       "24                                NaN               0.00                 NaN   \n",
       "29                                NaN                NaN                 NaN   \n",
       "30                                NaN                NaN                 NaN   \n",
       "31                                NaN                NaN                 NaN   \n",
       "32                                NaN                NaN                 NaN   \n",
       "...                               ...                ...                 ...   \n",
       "56093                             NaN                NaN                 NaN   \n",
       "56094                             NaN                NaN                 NaN   \n",
       "56095                             NaN                NaN                 NaN   \n",
       "56096                             NaN                NaN                 NaN   \n",
       "56097                             NaN                NaN                 NaN   \n",
       "\n",
       "       DailyAverageWindSpeed  HourlyWindSpeed DailySnowfall  \n",
       "24                       8.6              NaN           0.0  \n",
       "29                       NaN              8.0           NaN  \n",
       "30                       NaN              6.0           NaN  \n",
       "31                       NaN              5.0           NaN  \n",
       "32                       NaN              0.0           NaN  \n",
       "...                      ...              ...           ...  \n",
       "56093                    NaN              3.0           NaN  \n",
       "56094                    NaN              0.0           NaN  \n",
       "56095                    NaN              0.0           NaN  \n",
       "56096                    NaN              0.0           NaN  \n",
       "56097                    NaN              NaN           NaN  \n",
       "\n",
       "[8523 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_keep = ['DATE','LATITUDE', 'LONGITUDE', 'MonthlyTotalLiquidPrecipitation', 'DailyPrecipitation', 'HourlyPrecipitation', 'DailyAverageWindSpeed', 'HourlyWindSpeed', 'DailySnowfall']\n",
    "\n",
    "weather_data = get_all_weather_csvs(WEATHER_CSV_DIR)\n",
    "weather_data = weather_data[columns_to_keep]\n",
    "weather_data['DATE'] = pd.to_datetime(weather_data['DATE'])\n",
    "\n",
    "# weather_data[weather_data[\"DailyPrecipitation\"].isna()] #54343\n",
    "weather_data[weather_data[\"HourlyPrecipitation\"].isna()] #8,523\n",
    "# weather_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b32ee20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     DATE  LATITUDE  LONGITUDE  \\\n",
      "0     2020-01-01 00:51:00  40.77898  -73.96925   \n",
      "1     2020-01-01 01:51:00  40.77898  -73.96925   \n",
      "2     2020-01-01 02:51:00  40.77898  -73.96925   \n",
      "3     2020-01-01 03:51:00  40.77898  -73.96925   \n",
      "4     2020-01-01 04:51:00  40.77898  -73.96925   \n",
      "...                   ...       ...        ...   \n",
      "56073 2024-10-21 19:51:00  40.77898  -73.96925   \n",
      "56074 2024-10-21 20:51:00  40.77898  -73.96925   \n",
      "56075 2024-10-21 21:51:00  40.77898  -73.96925   \n",
      "56076 2024-10-21 22:51:00  40.77898  -73.96925   \n",
      "56077 2024-10-21 23:51:00  40.77898  -73.96925   \n",
      "\n",
      "      MonthlyTotalLiquidPrecipitation DailyPrecipitation HourlyPrecipitation  \\\n",
      "0                                 NaN                NaN                0.00   \n",
      "1                                 NaN                NaN                0.00   \n",
      "2                                 NaN                NaN                0.00   \n",
      "3                                 NaN                NaN                0.00   \n",
      "4                                 NaN                NaN                0.00   \n",
      "...                               ...                ...                 ...   \n",
      "56073                             NaN                NaN                0.00   \n",
      "56074                             NaN                NaN                0.00   \n",
      "56075                             NaN                NaN                0.00   \n",
      "56076                             NaN                NaN                0.00   \n",
      "56077                             NaN                NaN                0.00   \n",
      "\n",
      "       DailyAverageWindSpeed  HourlyWindSpeed DailySnowfall  \n",
      "0                        NaN              8.0           NaN  \n",
      "1                        NaN              8.0           NaN  \n",
      "2                        NaN             14.0           NaN  \n",
      "3                        NaN             11.0           NaN  \n",
      "4                        NaN              6.0           NaN  \n",
      "...                      ...              ...           ...  \n",
      "56073                    NaN              5.0           NaN  \n",
      "56074                    NaN              3.0           NaN  \n",
      "56075                    NaN              3.0           NaN  \n",
      "56076                    NaN              3.0           NaN  \n",
      "56077                    NaN              3.0           NaN  \n",
      "\n",
      "[47575 rows x 9 columns]\n",
      "Unique String Values and Their Counts in HourlyPrecipitation:\n",
      "HourlyPrecipitation\n",
      "0.00     36284\n",
      "T         3706\n",
      "0.01      1966\n",
      "0.02      1081\n",
      "0.03       752\n",
      "         ...  \n",
      "0.19s        1\n",
      "0.32s        1\n",
      "0.96         1\n",
      "0.81         1\n",
      "1.28s        1\n",
      "Name: count, Length: 143, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#We needed to do this because an error was being thrown that the hourly precipitation values were strings. \n",
    "# Identify rows where HourlyPrecipitation is a string\n",
    "string_precipitation_rows = weather_data[weather_data['HourlyPrecipitation'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "# Print or display the rows to inspect the problematic values\n",
    "print(string_precipitation_rows)\n",
    "# Identify rows where HourlyPrecipitation is a string\n",
    "string_precipitation_rows = weather_data[weather_data['HourlyPrecipitation'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "# Extract the HourlyPrecipitation values that are strings\n",
    "string_values = string_precipitation_rows['HourlyPrecipitation']\n",
    "\n",
    "# Get unique values and their count using value_counts()\n",
    "string_value_counts = string_values.value_counts()\n",
    "\n",
    "# Print or display the unique string values and their count\n",
    "print(\"Unique String Values and Their Counts in HourlyPrecipitation:\")\n",
    "print(string_value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e18763d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 DATE  LATITUDE  LONGITUDE MonthlyTotalLiquidPrecipitation  \\\n",
      "0 2020-01-01 00:51:00  40.77898  -73.96925                             NaN   \n",
      "1 2020-01-01 01:51:00  40.77898  -73.96925                             NaN   \n",
      "2 2020-01-01 02:51:00  40.77898  -73.96925                             NaN   \n",
      "3 2020-01-01 03:51:00  40.77898  -73.96925                             NaN   \n",
      "4 2020-01-01 04:51:00  40.77898  -73.96925                             NaN   \n",
      "\n",
      "  DailyPrecipitation  HourlyPrecipitation  DailyAverageWindSpeed  \\\n",
      "0                NaN                  0.0                    NaN   \n",
      "1                NaN                  0.0                    NaN   \n",
      "2                NaN                  0.0                    NaN   \n",
      "3                NaN                  0.0                    NaN   \n",
      "4                NaN                  0.0                    NaN   \n",
      "\n",
      "   HourlyWindSpeed DailySnowfall  \n",
      "0              8.0           NaN  \n",
      "1              8.0           NaN  \n",
      "2             14.0           NaN  \n",
      "3             11.0           NaN  \n",
      "4              6.0           NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_15944\\2630901844.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  weather_data['HourlyPrecipitation'].replace('T', 0.00, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Cleans out the string values based on different cases identified in the query above\n",
    "# Replace 'T' (trace amount) with 0.00\n",
    "weather_data['HourlyPrecipitation'].replace('T', 0.00, inplace=True)\n",
    "\n",
    "# Function to clean non-numeric characters from values\n",
    "def clean_precipitation_value(value):\n",
    "    if isinstance(value, str):\n",
    "        # Remove all non-numeric characters except the decimal point\n",
    "        return re.sub(r'[^0-9.]', '', value)\n",
    "    return value\n",
    "\n",
    "# Apply the cleaning function to the HourlyPrecipitation column\n",
    "weather_data['HourlyPrecipitation'] = weather_data['HourlyPrecipitation'].apply(clean_precipitation_value)\n",
    "\n",
    "# Convert all cleaned values to numeric, coercing any problematic ones to NaN\n",
    "weather_data['HourlyPrecipitation'] = pd.to_numeric(weather_data['HourlyPrecipitation'], errors='coerce')\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(weather_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42534e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the remaining null hourly precipiation values \n",
    "# Ensure that 'DATE' is in the correct datetime format\n",
    "weather_data['DATE'] = pd.to_datetime(weather_data['DATE'])\n",
    "\n",
    "# Add a column for just the date (without time), which will help with grouping\n",
    "weather_data['DATE_ONLY'] = weather_data['DATE'].dt.date\n",
    "# Group by each unique date\n",
    "daily_groups = weather_data.groupby('DATE_ONLY')\n",
    "\n",
    "# Loop over each group of a specific date and calculate the remaining precipitation to distribute\n",
    "for date, group in daily_groups:\n",
    "    # Get the daily precipitation for the current day\n",
    "    daily_precipitation = group['DailyPrecipitation'].iloc[0]\n",
    "    \n",
    "    # Calculate the sum of existing hourly precipitation values (if any)\n",
    "    existing_hourly_precip = group['HourlyPrecipitation'].sum(skipna=True)\n",
    "\n",
    "    # Calculate the remaining precipitation that needs to be distributed to missing hours\n",
    "    remaining_precip = daily_precipitation - existing_hourly_precip\n",
    "\n",
    "    # Get the number of hours with missing HourlyPrecipitation\n",
    "    missing_hours = group['HourlyPrecipitation'].isna().sum()\n",
    "\n",
    "    # Calculate how much to distribute to each missing hour\n",
    "    if missing_hours > 0 and remaining_precip > 0:\n",
    "        hourly_precipitation_to_assign = remaining_precip / missing_hours\n",
    "    else:\n",
    "        hourly_precipitation_to_assign = 0\n",
    "\n",
    "    # Fill missing HourlyPrecipitation values with the calculated amount\n",
    "    weather_data.loc[group.index, 'HourlyPrecipitation'] = group['HourlyPrecipitation'].fillna(hourly_precipitation_to_assign)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "79d7f715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>MonthlyTotalLiquidPrecipitation</th>\n",
       "      <th>DailyPrecipitation</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>DailyAverageWindSpeed</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "      <th>DailySnowfall</th>\n",
       "      <th>DATE_ONLY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [DATE, LATITUDE, LONGITUDE, MonthlyTotalLiquidPrecipitation, DailyPrecipitation, HourlyPrecipitation, DailyAverageWindSpeed, HourlyWindSpeed, DailySnowfall, DATE_ONLY]\n",
       "Index: []"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm there are no null hourly precipitation values anymore \n",
    "weather_data[weather_data[\"HourlyPrecipitation\"].isna()] #0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48216557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>MonthlyTotalLiquidPrecipitation</th>\n",
       "      <th>DailyPrecipitation</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>DailyAverageWindSpeed</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "      <th>DailySnowfall</th>\n",
       "      <th>DATE_ONLY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 01:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 02:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 03:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 04:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DATE  LATITUDE  LONGITUDE MonthlyTotalLiquidPrecipitation  \\\n",
       "0 2020-01-01 00:51:00  40.77898  -73.96925                             NaN   \n",
       "1 2020-01-01 01:51:00  40.77898  -73.96925                             NaN   \n",
       "2 2020-01-01 02:51:00  40.77898  -73.96925                             NaN   \n",
       "3 2020-01-01 03:51:00  40.77898  -73.96925                             NaN   \n",
       "4 2020-01-01 04:51:00  40.77898  -73.96925                             NaN   \n",
       "\n",
       "  DailyPrecipitation  HourlyPrecipitation  DailyAverageWindSpeed  \\\n",
       "0                NaN                  0.0                    NaN   \n",
       "1                NaN                  0.0                    NaN   \n",
       "2                NaN                  0.0                    NaN   \n",
       "3                NaN                  0.0                    NaN   \n",
       "4                NaN                  0.0                    NaN   \n",
       "\n",
       "   HourlyWindSpeed DailySnowfall   DATE_ONLY  \n",
       "0              8.0           NaN  2020-01-01  \n",
       "1              8.0           NaN  2020-01-01  \n",
       "2             14.0           NaN  2020-01-01  \n",
       "3             11.0           NaN  2020-01-01  \n",
       "4              6.0           NaN  2020-01-01  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a474f6e8-d4b4-409d-aade-c6b51b504666",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_columns_mapping = {\n",
    " 'DATE': 'date',\n",
    " 'LATITUDE': 'latitude',\n",
    " 'LONGITUDE': 'longitude',\n",
    " 'DailyPrecipitation': 'daily_precipitation',\n",
    " 'HourlyPrecipitation': 'hourly_precipitation',\n",
    " 'DailyAverageWindSpeed': 'daily_average_wind_speed',\n",
    " 'HourlyWindSpeed': 'hourly_wind_speed',\n",
    " 'DailySnowfall': 'daily_snowfall'\n",
    "}\n",
    "weather_data.rename(columns=weather_columns_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "935261b7-ae23-427c-97ff-ea31aa4e44c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56098 entries, 0 to 56097\n",
      "Data columns (total 10 columns):\n",
      " #   Column                           Non-Null Count  Dtype         \n",
      "---  ------                           --------------  -----         \n",
      " 0   date                             56098 non-null  datetime64[ns]\n",
      " 1   latitude                         56098 non-null  float64       \n",
      " 2   longitude                        56098 non-null  float64       \n",
      " 3   MonthlyTotalLiquidPrecipitation  52 non-null     object        \n",
      " 4   daily_precipitation              1755 non-null   object        \n",
      " 5   hourly_precipitation             56098 non-null  float64       \n",
      " 6   daily_average_wind_speed         1697 non-null   float64       \n",
      " 7   hourly_wind_speed                49660 non-null  float64       \n",
      " 8   daily_snowfall                   1750 non-null   object        \n",
      " 9   DATE_ONLY                        56098 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(5), object(4)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "weather_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a7dcb502-d1d1-447d-aa68-11bff0dc53b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>hourly_precipitation</th>\n",
       "      <th>daily_average_wind_speed</th>\n",
       "      <th>hourly_wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56098</td>\n",
       "      <td>5.609800e+04</td>\n",
       "      <td>5.609800e+04</td>\n",
       "      <td>56098.000000</td>\n",
       "      <td>1697.000000</td>\n",
       "      <td>49660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-05-29 21:14:19.618881024</td>\n",
       "      <td>4.077898e+01</td>\n",
       "      <td>-7.396925e+01</td>\n",
       "      <td>0.010511</td>\n",
       "      <td>5.000766</td>\n",
       "      <td>5.125453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 00:51:00</td>\n",
       "      <td>4.077898e+01</td>\n",
       "      <td>-7.396925e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-03-18 19:01:45</td>\n",
       "      <td>4.077898e+01</td>\n",
       "      <td>-7.396925e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-05-28 01:21:00</td>\n",
       "      <td>4.077898e+01</td>\n",
       "      <td>-7.396925e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-08-15 05:39:00</td>\n",
       "      <td>4.077898e+01</td>\n",
       "      <td>-7.396925e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-10-22 18:51:00</td>\n",
       "      <td>4.077898e+01</td>\n",
       "      <td>-7.396925e+01</td>\n",
       "      <td>3.470000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>2237.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.214267e-11</td>\n",
       "      <td>5.815134e-11</td>\n",
       "      <td>0.056783</td>\n",
       "      <td>2.339258</td>\n",
       "      <td>14.653212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                date      latitude     longitude  \\\n",
       "count                          56098  5.609800e+04  5.609800e+04   \n",
       "mean   2022-05-29 21:14:19.618881024  4.077898e+01 -7.396925e+01   \n",
       "min              2020-01-01 00:51:00  4.077898e+01 -7.396925e+01   \n",
       "25%              2021-03-18 19:01:45  4.077898e+01 -7.396925e+01   \n",
       "50%              2022-05-28 01:21:00  4.077898e+01 -7.396925e+01   \n",
       "75%              2023-08-15 05:39:00  4.077898e+01 -7.396925e+01   \n",
       "max              2024-10-22 18:51:00  4.077898e+01 -7.396925e+01   \n",
       "std                              NaN  4.214267e-11  5.815134e-11   \n",
       "\n",
       "       hourly_precipitation  daily_average_wind_speed  hourly_wind_speed  \n",
       "count          56098.000000               1697.000000       49660.000000  \n",
       "mean               0.010511                  5.000766           5.125453  \n",
       "min                0.000000                  0.600000           0.000000  \n",
       "25%                0.000000                  3.200000           3.000000  \n",
       "50%                0.000000                  4.600000           5.000000  \n",
       "75%                0.000000                  6.300000           7.000000  \n",
       "max                3.470000                 14.200000        2237.000000  \n",
       "std                0.056783                  2.339258          14.653212  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS hourly_weather (\n",
    "    date DATETIME,\n",
    "    latitude REAL,\n",
    "    longitude REAL,\n",
    "    hourly_precipitation REAL,\n",
    "    hourly_wind_speed REAL,\n",
    "    daily_snowfall REAL\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS daily_weather (\n",
    "    date DATETIME,\n",
    "    latitude REAL,\n",
    "    longitude REAL,\n",
    "    daily_precipitation REAL,\n",
    "    daily_wind_speed REAL,\n",
    "    daily_snowfall REAL\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS taxi_trips (\n",
    "    pickup_datetime DATETIME,\n",
    "    dropoff_datetime DATETIME,\n",
    "    trip_distance REAL,\n",
    "    rate_code_id INTEGER,\n",
    "    pickup_location_id INTEGER,\n",
    "    dropoff_location_id INTEGER,\n",
    "    base_passenger_fare REAL,\n",
    "    rush_hour_surcharge REAL,\n",
    "    mta_tax REAL,\n",
    "    tip_amount REAL,\n",
    "    tolls_amount REAL,\n",
    "    improvement_surcharge REAL,\n",
    "    total_amount REAL,\n",
    "    congestion_surcharge REAL,\n",
    "    airport_fee REAL\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# might not need request_datetime\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS uber_trips (\n",
    "    request_datetime DATETIME,\n",
    "    pickup_datetime DATETIME,\n",
    "    dropoff_datetime DATETIME,\n",
    "    trip_distance REAL,\n",
    "    pickup_location_id INTEGER,\n",
    "    dropoff_location_id INTEGER,\n",
    "    base_passenger_fare REAL,\n",
    "    tip_amount REAL,\n",
    "    tolls_amount REAL,\n",
    "    black_car_fund_fee REAL,\n",
    "    total_amount REAL,\n",
    "    sales_tax, REAL\n",
    "    congestion_surcharge REAL,\n",
    "    airport_fee REAL\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    with open(DATABASE_SCHEMA_FILE, 'r') as schema_file:\n",
    "        schema = schema_file.read()\n",
    "        connection.execute(db.text(schema))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956de52a-169e-456d-be1f-4ea57b4104d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_taxi_data, uber_data, hourly_weather_data, daily_weather_data\n",
    "\n",
    "# Load sampled trip data into each database\n",
    "final_taxi_data.to_sql('taxi_trips', con=engine, if_exists='replace', index=False)\n",
    "final_uber_data.to_sql('uber_trips', con=engine, if_exists='replace', index=False)\n",
    "hourly_weather_data.to_sql('hourly_weather', con=engine, if_exists='replace', index=False)\n",
    "daily_weather_data.to_sql('daily_weather', con=engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(table_to_df_dict):\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_data,\n",
    "    \"daily_weather\": daily_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74004f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(map_table_name_to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = \"\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "TODO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute query either via sqlalchemy\n",
    "with engine.connect() as con:\n",
    "    results = con.execute(db.text(QUERY_1)).fetchall()\n",
    "results\n",
    "\n",
    "# or via pandas\n",
    "pd.read_sql(QUERY_1, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_1(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
